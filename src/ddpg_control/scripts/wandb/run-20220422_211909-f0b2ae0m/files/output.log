State Dimensions: 364
Action Dimensions: 2
Action Max: 0.2 m/s and 1 rad/s
---------------------- EPISODE 1 --------------------
waiting for service
reset called
[INFO] [1650676752.277313, 0.765000]: Goal position : 0.6, 0.0
0.6 0.0
torch.Size([364])
step: 1 | reward: -8.0 | done: False | action: 0.16195765137672424,0.5331308245658875
torch.Size([364])
step: 2 | reward: 2.0000000000000018 | done: False | action: 0.18020616471767426,0.45145782828330994
torch.Size([364])
step: 3 | reward: 7.999999999999985 | done: False | action: 0.18157853186130524,0.33370205760002136
torch.Size([364])
step: 4 | reward: 6.000000000000005 | done: False | action: 0.1904219686985016,0.3021034002304077
torch.Size([364])
step: 5 | reward: 6.000000000000005 | done: False | action: 0.1765681356191635,0.24115167558193207
torch.Size([364])
step: 6 | reward: 7.9999999999999964 | done: False | action: 0.17977185547351837,0.29604777693748474
torch.Size([364])
step: 7 | reward: 8.000000000000007 | done: False | action: 0.17007026076316833,0.4361627697944641
torch.Size([364])
step: 8 | reward: 5.999999999999995 | done: False | action: 0.1749890297651291,0.3536578118801117
torch.Size([364])
step: 9 | reward: 4.0000000000000036 | done: False | action: 0.17824724316596985,0.6182408332824707
torch.Size([364])
step: 10 | reward: 5.999999999999995 | done: False | action: 0.18737517297267914,0.7185662984848022
torch.Size([364])
step: 11 | reward: 6.000000000000005 | done: False | action: 0.18524496257305145,0.8994961380958557
torch.Size([364])
step: 12 | reward: 2.0000000000000018 | done: False | action: 0.1808372586965561,0.8381546139717102
torch.Size([364])
step: 13 | reward: 1.9999999999999907 | done: False | action: 0.18336692452430725,0.626240074634552
torch.Size([364])
step: 14 | reward: -8.0 | done: False | action: 0.18483778834342957,0.750234842300415
torch.Size([364])
step: 15 | reward: -8.0 | done: False | action: 0.18466195464134216,0.5964239239692688
torch.Size([364])
step: 16 | reward: -8.0 | done: False | action: 0.1781209409236908,0.654093861579895
torch.Size([364])
step: 17 | reward: -8.0 | done: False | action: 0.17706795036792755,0.5610266923904419
torch.Size([364])
step: 18 | reward: -8.0 | done: False | action: 0.1771940141916275,0.4381038546562195
torch.Size([364])
step: 19 | reward: -8.0 | done: False | action: 0.17294922471046448,0.493599534034729
torch.Size([364])
step: 20 | reward: -8.0 | done: False | action: 0.17053911089897156,0.4745923578739166
torch.Size([364])
step: 21 | reward: -8.0 | done: False | action: 0.1747136414051056,0.5831593871116638
torch.Size([364])
step: 22 | reward: -8.0 | done: False | action: 0.17379531264305115,0.5875526666641235
torch.Size([364])
step: 23 | reward: -8.0 | done: False | action: 0.18430081009864807,0.5061008334159851
torch.Size([364])
step: 24 | reward: -8.0 | done: False | action: 0.20000000298023224,0.5704903602600098
torch.Size([364])
step: 25 | reward: -8.0 | done: False | action: 0.20000000298023224,0.6348791718482971
torch.Size([364])
step: 26 | reward: -8.0 | done: False | action: 0.20000000298023224,0.3977004885673523
torch.Size([364])
step: 27 | reward: -8.0 | done: False | action: 0.20000000298023224,0.3772212266921997
torch.Size([364])
step: 28 | reward: -8.0 | done: False | action: 0.20000000298023224,0.24230466783046722
torch.Size([364])
step: 29 | reward: -8.0 | done: False | action: 0.20000000298023224,0.3422943949699402
torch.Size([364])
step: 30 | reward: -8.0 | done: False | action: 0.20000000298023224,0.3806530237197876
torch.Size([364])
step: 31 | reward: -8.0 | done: False | action: 0.18119479715824127,0.5049406290054321
torch.Size([364])
step: 32 | reward: -8.0 | done: False | action: 0.16545143723487854,0.4286506474018097
torch.Size([364])
step: 33 | reward: -8.0 | done: False | action: 0.16522257030010223,0.4688020944595337
torch.Size([364])
step: 34 | reward: -8.0 | done: False | action: 0.16487009823322296,0.6141480803489685
torch.Size([364])
step: 35 | reward: -8.0 | done: False | action: 0.17276959121227264,0.6135823130607605
torch.Size([364])
step: 36 | reward: -8.0 | done: False | action: 0.17794080078601837,0.5473830103874207
torch.Size([364])
step: 37 | reward: -8.0 | done: False | action: 0.16326743364334106,0.5949500203132629
torch.Size([364])
step: 38 | reward: -8.0 | done: False | action: 0.16538675129413605,0.8054073452949524
torch.Size([364])
step: 39 | reward: -8.0 | done: False | action: 0.16301791369915009,0.907599151134491
torch.Size([364])
step: 40 | reward: -8.0 | done: False | action: 0.15160049498081207,0.9036707878112793
torch.Size([364])
step: 41 | reward: -8.0 | done: False | action: 0.15114519000053406,0.7577937245368958
torch.Size([364])
step: 42 | reward: -8.0 | done: False | action: 0.15311680734157562,0.7566861510276794
torch.Size([364])
step: 43 | reward: 2.0000000000000018 | done: False | action: 0.16602888703346252,0.6368090510368347
torch.Size([364])
step: 44 | reward: 2.0000000000000018 | done: False | action: 0.15341517329216003,0.6352235078811646
torch.Size([364])
step: 45 | reward: 2.0000000000000018 | done: False | action: 0.14299455285072327,0.4824528992176056
torch.Size([364])
step: 46 | reward: 2.0000000000000018 | done: False | action: 0.15172624588012695,0.3973711133003235
torch.Size([364])
step: 47 | reward: 3.9999999999999813 | done: False | action: 0.1600780487060547,0.34030094742774963
torch.Size([364])
step: 48 | reward: 2.0000000000000018 | done: False | action: 0.1584625244140625,0.41237083077430725
torch.Size([364])
step: 49 | reward: 4.0000000000000036 | done: False | action: 0.17422892153263092,0.35065364837646484
torch.Size([364])
step: 50 | reward: 4.0000000000000036 | done: False | action: 0.15903642773628235,0.4678674340248108
torch.Size([364])
step: 51 | reward: 4.0000000000000036 | done: False | action: 0.15999387204647064,0.6965140700340271
torch.Size([364])
step: 52 | reward: 6.000000000000005 | done: False | action: 0.15918870270252228,0.8188327550888062
torch.Size([364])
step: 53 | reward: 3.9999999999999813 | done: False | action: 0.14761267602443695,0.7160305380821228
torch.Size([364])
step: 54 | reward: 4.0000000000000036 | done: False | action: 0.1451016664505005,0.6478325128555298
torch.Size([364])
step: 55 | reward: 4.0000000000000036 | done: False | action: 0.15161491930484772,0.281139999628067
torch.Size([364])
step: 56 | reward: 8.000000000000007 | done: False | action: 0.15886574983596802,0.3486425578594208
torch.Size([364])
step: 57 | reward: 6.000000000000005 | done: False | action: 0.16031089425086975,0.26723432540893555
torch.Size([364])
step: 58 | reward: 5.999999999999983 | done: False | action: 0.14906449615955353,0.17216064035892487
torch.Size([364])
step: 59 | reward: 6.000000000000005 | done: False | action: 0.1502438187599182,0.23702557384967804
torch.Size([364])
step: 60 | reward: 6.000000000000005 | done: False | action: 0.16430123150348663,0.1864638775587082
torch.Size([364])
step: 61 | reward: 6.000000000000005 | done: False | action: 0.15553367137908936,0.1006808951497078
torch.Size([364])
step: 62 | reward: 5.999999999999983 | done: False | action: 0.14253482222557068,-0.011796052567660809
torch.Size([364])
step: 63 | reward: 4.0000000000000036 | done: False | action: 0.13830889761447906,0.0040717399679124355
torch.Size([364])
step: 64 | reward: 6.000000000000005 | done: False | action: 0.1368473768234253,-0.004349078517407179
torch.Size([364])
step: 65 | reward: 4.0000000000000036 | done: False | action: 0.13991162180900574,0.16550672054290771
torch.Size([364])
step: 66 | reward: 7.9999999999999964 | done: False | action: 0.13642846047878265,0.12588728964328766
torch.Size([364])
step: 67 | reward: 4.0000000000000036 | done: False | action: 0.13611821830272675,-0.08845150470733643
torch.Size([364])
step: 68 | reward: 5.999999999999995 | done: False | action: 0.12685829401016235,-0.07269273698329926
torch.Size([364])
step: 69 | reward: 6.000000000000005 | done: False | action: 0.13945184648036957,-0.012638500891625881
torch.Size([364])
step: 70 | reward: 3.9999999999999925 | done: False | action: 0.14419163763523102,0.04639293625950813
torch.Size([364])
step: 71 | reward: 8.000000000000007 | done: False | action: 0.1403549760580063,0.10041182488203049
torch.Size([364])
step: 72 | reward: 5.999999999999995 | done: False | action: 0.14348182082176208,0.1314581334590912
torch.Size([364])
step: 73 | reward: 4.0000000000000036 | done: False | action: 0.14282724261283875,0.1880636066198349
torch.Size([364])
step: 74 | reward: 3.9999999999999982 | done: False | action: 0.15102453529834747,0.2307591289281845
torch.Size([364])
step: 75 | reward: 10.000000000000004 | done: False | action: 0.17099586129188538,0.41886407136917114
torch.Size([364])
step: 76 | reward: 3.9999999999999982 | done: False | action: 0.18536800146102905,0.451391339302063
torch.Size([364])
[INFO] [1650676767.710141, 16.011000]: Goal!!
[INFO] [1650676768.558285, 16.820000]: Goal position : 0.3, -1.1
step: 77 | reward: 100.0 | done: True | action: 0.18897253274917603,0.4411693513393402
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 2 --------------------
waiting for service
reset called
[INFO] [1650676769.788830, 1.182000]: Goal position : 1.2, 0.8
1.2 0.8
torch.Size([364])
step: 78 | reward: -8.0 | done: False | action: 0.18624496459960938,0.9020748138427734
torch.Size([364])
step: 79 | reward: 2.0000000000000018 | done: False | action: 0.1966014802455902,0.9769160747528076
torch.Size([364])
step: 80 | reward: 4.0000000000000036 | done: False | action: 0.195700541138649,0.8728059530258179
torch.Size([364])
step: 81 | reward: 7.999999999999963 | done: False | action: 0.1924981027841568,0.7247036695480347
torch.Size([364])
step: 82 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,0.8927432298660278
torch.Size([364])
step: 83 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 84 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 85 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,0.9531473517417908
torch.Size([364])
step: 86 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,0.7352550029754639
torch.Size([364])
step: 87 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,0.7689999938011169
torch.Size([364])
step: 88 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,0.6892877817153931
torch.Size([364])
step: 89 | reward: 3.999999999999959 | done: False | action: 0.20000000298023224,0.7058907151222229
torch.Size([364])
step: 90 | reward: 4.0000000000000036 | done: False | action: 0.19697904586791992,0.6683968901634216
torch.Size([364])
step: 91 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,0.7589117288589478
torch.Size([364])
step: 92 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,0.8879755139350891
torch.Size([364])
step: 93 | reward: -8.0 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 94 | reward: -8.0 | done: False | action: 0.20000000298023224,0.911163330078125
torch.Size([364])
step: 95 | reward: -8.0 | done: False | action: 0.1878899335861206,0.949292004108429
torch.Size([364])
step: 96 | reward: -8.0 | done: False | action: 0.17339952290058136,0.932970404624939
torch.Size([364])
step: 97 | reward: -8.0 | done: False | action: 0.16943319141864777,1.0
torch.Size([364])
step: 98 | reward: -8.0 | done: False | action: 0.18220682442188263,1.0
torch.Size([364])
step: 99 | reward: -8.0 | done: False | action: 0.16983985900878906,0.9361975789070129
torch.Size([364])
step: 100 | reward: -8.0 | done: False | action: 0.1746504306793213,1.0
torch.Size([364])
step: 101 | reward: -8.0 | done: False | action: 0.19700896739959717,0.9438156485557556
torch.Size([364])
step: 102 | reward: -8.0 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 103 | reward: -8.0 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 104 | reward: -8.0 | done: False | action: 0.20000000298023224,0.7380826473236084
torch.Size([364])
step: 105 | reward: -8.0 | done: False | action: 0.19933158159255981,0.7532156705856323
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 106 | reward: -8.0 | done: False | action: 0.17636308073997498,0.9204649925231934
torch.Size([364])
step: 107 | reward: -8.0 | done: False | action: 0.16094526648521423,0.8234775066375732
torch.Size([364])
step: 108 | reward: -8.0 | done: False | action: 0.17615169286727905,0.6597520112991333
torch.Size([364])
step: 109 | reward: -8.0 | done: False | action: 0.17069576680660248,0.7378243803977966
torch.Size([364])
step: 110 | reward: -8.0 | done: False | action: 0.1720643788576126,0.8276130557060242
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 111 | reward: 25.99999999999998 | done: False | action: 0.19138291478157043,-0.9001634120941162
torch.Size([364])
step: 112 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7831697463989258
torch.Size([364])
step: 113 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.973927915096283
torch.Size([364])
step: 114 | reward: 4.0000000000000036 | done: False | action: 0.18336249887943268,-0.969027042388916
torch.Size([364])
step: 115 | reward: 2.0000000000000018 | done: False | action: 0.18608979880809784,-0.9224468469619751
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 116 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8432464599609375
torch.Size([364])
step: 117 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8470135927200317
torch.Size([364])
step: 118 | reward: -8.0 | done: False | action: 0.18774870038032532,-0.9538090229034424
torch.Size([364])
step: 119 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9202440977096558
torch.Size([364])
step: 120 | reward: -8.0 | done: False | action: 0.19233587384223938,-0.8288969993591309
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 121 | reward: -8.0 | done: False | action: 0.19500499963760376,-0.8422809839248657
torch.Size([364])
step: 122 | reward: -8.0 | done: False | action: 0.18037687242031097,-0.6366907358169556
torch.Size([364])
step: 123 | reward: -8.0 | done: False | action: 0.18498142063617706,-0.7058877944946289
torch.Size([364])
step: 124 | reward: -8.0 | done: False | action: 0.1840035617351532,-0.8577321767807007
torch.Size([364])
step: 125 | reward: -8.0 | done: False | action: 0.17922042310237885,-0.7184671759605408
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 126 | reward: -8.0 | done: False | action: 0.19398732483386993,-0.793802797794342
torch.Size([364])
step: 127 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8937274217605591
torch.Size([364])
step: 128 | reward: -8.0 | done: False | action: 0.19808797538280487,-0.9747743606567383
torch.Size([364])
step: 129 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 130 | reward: -8.0 | done: False | action: 0.19720128178596497,-0.9147549271583557
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 131 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8241918087005615
torch.Size([364])
step: 132 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8557578921318054
torch.Size([364])
step: 133 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8953661918640137
torch.Size([364])
step: 134 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9089339375495911
torch.Size([364])
step: 135 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9651390314102173
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 136 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9255533218383789
torch.Size([364])
step: 137 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 138 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 139 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 140 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8903292417526245
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 141 | reward: 18.000000000000014 | done: False | action: 0.18970336019992828,1.0
torch.Size([364])
step: 142 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 143 | reward: 6.000000000000005 | done: False | action: 0.1955144703388214,1.0
torch.Size([364])
step: 144 | reward: 9.999999999999964 | done: False | action: 0.19092503190040588,1.0
torch.Size([364])
step: 145 | reward: 6.000000000000005 | done: False | action: 0.19863180816173553,1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 146 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 147 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 148 | reward: 6.000000000000005 | done: False | action: 0.19856272637844086,1.0
torch.Size([364])
step: 149 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,1.0
torch.Size([364])
step: 150 | reward: -8.0 | done: False | action: 0.18693654239177704,1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 151 | reward: -8.0 | done: False | action: 0.1923629343509674,0.8577249646186829
torch.Size([364])
step: 152 | reward: -8.0 | done: False | action: 0.18107366561889648,0.8954623937606812
torch.Size([364])
step: 153 | reward: -8.0 | done: False | action: 0.15906068682670593,0.8450310826301575
torch.Size([364])
step: 154 | reward: -8.0 | done: False | action: 0.15657414495944977,0.8302715420722961
torch.Size([364])
step: 155 | reward: -8.0 | done: False | action: 0.1563328504562378,0.805377185344696
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 156 | reward: -8.0 | done: False | action: 0.15096847712993622,0.7673838138580322
torch.Size([364])
step: 157 | reward: -8.0 | done: False | action: 0.16552990674972534,0.8882322907447815
torch.Size([364])
step: 158 | reward: -8.0 | done: False | action: 0.17422117292881012,0.761874258518219
torch.Size([364])
step: 159 | reward: -8.0 | done: False | action: 0.1680118888616562,0.7697484493255615
torch.Size([364])
step: 160 | reward: -8.0 | done: False | action: 0.16205741465091705,0.754800021648407
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 161 | reward: -8.0 | done: False | action: 0.1660623848438263,0.9806215167045593
torch.Size([364])
step: 162 | reward: -8.0 | done: False | action: 0.1628541350364685,0.8751330375671387
torch.Size([364])
step: 163 | reward: -8.0 | done: False | action: 0.1872200071811676,0.9397128820419312
torch.Size([364])
step: 164 | reward: -8.0 | done: False | action: 0.1924811452627182,1.0
torch.Size([364])
step: 165 | reward: -8.0 | done: False | action: 0.20000000298023224,1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 166 | reward: -8.0 | done: False | action: 0.19018465280532837,1.0
torch.Size([364])
step: 167 | reward: -8.0 | done: False | action: 0.18088452517986298,1.0
torch.Size([364])
step: 168 | reward: 2.0000000000000018 | done: False | action: 0.1850540041923523,1.0
torch.Size([364])
step: 169 | reward: 4.0000000000000036 | done: False | action: 0.19906561076641083,1.0
torch.Size([364])
step: 170 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 171 | reward: 12.00000000000001 | done: False | action: 0.1969546526670456,-0.12927161157131195
torch.Size([364])
step: 172 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.2505818009376526
torch.Size([364])
step: 173 | reward: 8.000000000000007 | done: False | action: 0.19980919361114502,-0.3665156066417694
torch.Size([364])
step: 174 | reward: 5.999999999999961 | done: False | action: 0.19257831573486328,-0.26434844732284546
torch.Size([364])
step: 175 | reward: 6.000000000000005 | done: False | action: 0.19850146770477295,-0.30757761001586914
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 176 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.27012115716934204
torch.Size([364])
step: 177 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.25439393520355225
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 3 --------------------
waiting for service
reset called
[INFO] [1650676794.081058, 1.182000]: Goal position : 0.1, -1.0
0.1 -1.0
torch.Size([364])
step: 178 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.4085150957107544
torch.Size([364])
step: 179 | reward: -8.0 | done: False | action: 0.1983339786529541,-0.5049542784690857
torch.Size([364])
step: 180 | reward: -8.0 | done: False | action: 0.19465291500091553,-0.5214201807975769
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 181 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 182 | reward: 2.0000000000000018 | done: False | action: 0.19939647614955902,-1.0
torch.Size([364])
step: 183 | reward: 6.000000000000005 | done: False | action: 0.19489407539367676,-1.0
torch.Size([364])
step: 184 | reward: 3.9999999999999813 | done: False | action: 0.17700600624084473,-1.0
torch.Size([364])
step: 185 | reward: 4.0000000000000036 | done: False | action: 0.17407575249671936,-0.936802089214325
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 186 | reward: 6.000000000000005 | done: False | action: 0.18018832802772522,-0.9142639636993408
torch.Size([364])
step: 187 | reward: 8.000000000000007 | done: False | action: 0.1758379489183426,-0.7718666791915894
torch.Size([364])
step: 188 | reward: 5.999999999999983 | done: False | action: 0.1695147156715393,-0.8404089212417603
torch.Size([364])
step: 189 | reward: 8.000000000000007 | done: False | action: 0.18227159976959229,-0.9590549468994141
torch.Size([364])
step: 190 | reward: 6.000000000000005 | done: False | action: 0.17956264317035675,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 191 | reward: 19.999999999999996 | done: False | action: 0.16274459660053253,-0.9981328248977661
torch.Size([364])
step: 192 | reward: 4.0000000000000036 | done: False | action: 0.18109002709388733,-1.0
torch.Size([364])
step: 193 | reward: 4.0000000000000036 | done: False | action: 0.19132955372333527,-0.8238118886947632
torch.Size([364])
step: 194 | reward: -8.0 | done: False | action: 0.1902690827846527,-0.6390281319618225
torch.Size([364])
step: 195 | reward: -8.0 | done: False | action: 0.18713533878326416,-0.7863431572914124
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 196 | reward: -8.0 | done: False | action: 0.1803591549396515,-0.8022883534431458
torch.Size([364])
step: 197 | reward: -8.0 | done: False | action: 0.18507488071918488,-0.8666662573814392
torch.Size([364])
step: 198 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8171951770782471
torch.Size([364])
step: 199 | reward: -8.0 | done: False | action: 0.19448672235012054,-0.6283677220344543
torch.Size([364])
step: 200 | reward: -8.0 | done: False | action: 0.19000470638275146,-0.6303021907806396
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 201 | reward: -8.0 | done: False | action: 0.19092613458633423,-0.5878125429153442
torch.Size([364])
step: 202 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.5233651399612427
torch.Size([364])
step: 203 | reward: -8.0 | done: False | action: 0.1969648003578186,-0.40502241253852844
torch.Size([364])
step: 204 | reward: -8.0 | done: False | action: 0.1943376213312149,-0.40632346272468567
torch.Size([364])
step: 205 | reward: -8.0 | done: False | action: 0.1995881050825119,-0.63347989320755
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 206 | reward: -8.0 | done: False | action: 0.19587735831737518,-0.6669802665710449
torch.Size([364])
step: 207 | reward: -8.0 | done: False | action: 0.19202126562595367,-0.7207140922546387
torch.Size([364])
step: 208 | reward: -8.0 | done: False | action: 0.19256773591041565,-0.7316277027130127
torch.Size([364])
step: 209 | reward: -8.0 | done: False | action: 0.1832890808582306,-0.6887967586517334
torch.Size([364])
step: 210 | reward: -8.0 | done: False | action: 0.18985997140407562,-0.7065292000770569
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 211 | reward: -8.0 | done: False | action: 0.18873587250709534,-0.835381031036377
torch.Size([364])
step: 212 | reward: -8.0 | done: False | action: 0.1868004947900772,-0.9259856343269348
torch.Size([364])
step: 213 | reward: -8.0 | done: False | action: 0.16320936381816864,-1.0
torch.Size([364])
step: 214 | reward: -8.0 | done: False | action: 0.1658039540052414,-1.0
torch.Size([364])
step: 215 | reward: 2.0000000000000018 | done: False | action: 0.15726615488529205,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 216 | reward: 2.0000000000000018 | done: False | action: 0.16452090442180634,-1.0
torch.Size([364])
step: 217 | reward: 4.0000000000000036 | done: False | action: 0.17149417102336884,-1.0
torch.Size([364])
step: 218 | reward: 5.999999999999961 | done: False | action: 0.1832587569952011,-1.0
torch.Size([364])
step: 219 | reward: 4.0000000000000036 | done: False | action: 0.1707201451063156,-1.0
torch.Size([364])
step: 220 | reward: 6.000000000000005 | done: False | action: 0.18510113656520844,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 221 | reward: 16.000000000000014 | done: False | action: 0.19080519676208496,-1.0
torch.Size([364])
step: 222 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 223 | reward: 5.999999999999983 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 224 | reward: 8.000000000000007 | done: False | action: 0.19023345410823822,-1.0
torch.Size([364])
step: 225 | reward: 6.000000000000005 | done: False | action: 0.1997383087873459,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 226 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.972248911857605
torch.Size([364])
step: 227 | reward: 1.9999999999999796 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 228 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8831679224967957
torch.Size([364])
step: 229 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8577085733413696
torch.Size([364])
step: 230 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8511212468147278
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 231 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9366574287414551
torch.Size([364])
step: 232 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9889152646064758
torch.Size([364])
step: 233 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 234 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9985571503639221
torch.Size([364])
step: 235 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 236 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 237 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 238 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9207223653793335
torch.Size([364])
step: 239 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9319671392440796
torch.Size([364])
step: 240 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8855161666870117
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 241 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 242 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9096587896347046
torch.Size([364])
step: 243 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9713377952575684
torch.Size([364])
step: 244 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9232643842697144
torch.Size([364])
step: 245 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8864676356315613
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 246 | reward: 4.0000000000000036 | done: False | action: 0.19068413972854614,-0.9929796457290649
torch.Size([364])
step: 247 | reward: 2.0000000000000018 | done: False | action: 0.18956737220287323,-1.0
torch.Size([364])
step: 248 | reward: 6.000000000000005 | done: False | action: 0.18119212985038757,-1.0
torch.Size([364])
step: 249 | reward: 7.999999999999963 | done: False | action: 0.19599081575870514,-1.0
torch.Size([364])
step: 250 | reward: 6.000000000000005 | done: False | action: 0.1939588189125061,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 251 | reward: 16.000000000000014 | done: False | action: 0.18817013502120972,-1.0
torch.Size([364])
step: 252 | reward: 8.000000000000007 | done: False | action: 0.18484124541282654,-1.0
torch.Size([364])
step: 253 | reward: 7.999999999999985 | done: False | action: 0.1945161521434784,-0.9161129593849182
torch.Size([364])
step: 254 | reward: 6.000000000000005 | done: False | action: 0.18960249423980713,-0.9785284399986267
torch.Size([364])
step: 255 | reward: 6.000000000000005 | done: False | action: 0.18979412317276,-0.9721234440803528
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 256 | reward: 4.0000000000000036 | done: False | action: 0.19422711431980133,-0.9092437624931335
torch.Size([364])
step: 257 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9194654822349548
torch.Size([364])
step: 258 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9006052613258362
torch.Size([364])
step: 259 | reward: -8.0 | done: False | action: 0.19399496912956238,-0.8331400156021118
torch.Size([364])
step: 260 | reward: -8.0 | done: False | action: 0.19444426894187927,-0.8982941508293152
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 261 | reward: -8.0 | done: False | action: 0.1922856569290161,-0.8129879832267761
torch.Size([364])
step: 262 | reward: -8.0 | done: False | action: 0.18138283491134644,-0.9219935536384583
torch.Size([364])
step: 263 | reward: -8.0 | done: False | action: 0.18190400302410126,-0.9185743927955627
torch.Size([364])
step: 264 | reward: -8.0 | done: False | action: 0.17962612211704254,-1.0
torch.Size([364])
step: 265 | reward: -8.0 | done: False | action: 0.17546464502811432,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 266 | reward: -8.0 | done: False | action: 0.16714999079704285,-1.0
torch.Size([364])
step: 267 | reward: -8.0 | done: False | action: 0.16462427377700806,-1.0
torch.Size([364])
step: 268 | reward: -8.0 | done: False | action: 0.15673069655895233,-1.0
torch.Size([364])
step: 269 | reward: -8.0 | done: False | action: 0.16770771145820618,-1.0
torch.Size([364])
step: 270 | reward: -8.0 | done: False | action: 0.16497445106506348,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 271 | reward: -8.0 | done: False | action: 0.16433212161064148,-1.0
torch.Size([364])
step: 272 | reward: -8.0 | done: False | action: 0.17607007920742035,-1.0
torch.Size([364])
step: 273 | reward: 2.0000000000000018 | done: False | action: 0.18239694833755493,-1.0
torch.Size([364])
step: 274 | reward: 2.0000000000000018 | done: False | action: 0.18623441457748413,-1.0
torch.Size([364])
step: 275 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9874553084373474
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 276 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 277 | reward: 5.999999999999961 | done: False | action: 0.19996652007102966,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 4 --------------------
waiting for service
reset called
[INFO] [1650676818.168640, 1.042000]: Goal position : -0.5, 0.0
-0.5 0.0
torch.Size([364])
step: 278 | reward: -8.0 | done: False | action: 0.191502183675766,-0.9650110006332397
torch.Size([364])
step: 279 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8446175456047058
torch.Size([364])
step: 280 | reward: -8.0 | done: False | action: 0.18652774393558502,-0.7403583526611328
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 281 | reward: -8.0 | done: False | action: 0.19640812277793884,-0.7671505212783813
torch.Size([364])
step: 282 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 283 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9649718403816223
torch.Size([364])
step: 284 | reward: -8.0 | done: False | action: 0.19810089468955994,-0.9069017171859741
torch.Size([364])
step: 285 | reward: -8.0 | done: False | action: 0.1988297402858734,-0.8643904328346252
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 286 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 287 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 288 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 289 | reward: -8.0 | done: False | action: 0.19420085847377777,-1.0
torch.Size([364])
step: 290 | reward: -8.0 | done: False | action: 0.1936803013086319,-0.9938027262687683
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 291 | reward: 5.999999999999983 | done: False | action: 0.19802173972129822,-0.7936134934425354
torch.Size([364])
step: 292 | reward: 2.0000000000000018 | done: False | action: 0.19779933989048004,-0.7409732341766357
torch.Size([364])
step: 293 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.5552868247032166
torch.Size([364])
step: 294 | reward: 4.0000000000000036 | done: False | action: 0.1901683360338211,-0.6282056570053101
torch.Size([364])
step: 295 | reward: 6.000000000000005 | done: False | action: 0.1917116343975067,-0.6126646399497986
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 296 | reward: 3.9999999999999813 | done: False | action: 0.17280161380767822,-0.6249731183052063
torch.Size([364])
step: 297 | reward: 6.000000000000005 | done: False | action: 0.18435324728488922,-0.4939723610877991
torch.Size([364])
step: 298 | reward: 6.000000000000005 | done: False | action: 0.18371181190013885,-0.6235415935516357
torch.Size([364])
step: 299 | reward: 8.000000000000007 | done: False | action: 0.19538789987564087,-0.637274980545044
torch.Size([364])
step: 300 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-0.7236738204956055
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 301 | reward: 16.000000000000004 | done: False | action: 0.18260613083839417,-0.8048093914985657
torch.Size([364])
step: 302 | reward: 8.000000000000007 | done: False | action: 0.17058143019676208,-1.0
torch.Size([364])
step: 303 | reward: 5.999999999999995 | done: False | action: 0.17699585855007172,-0.8844044804573059
torch.Size([364])
step: 304 | reward: 6.000000000000005 | done: False | action: 0.1661335974931717,-0.965455174446106
torch.Size([364])
step: 305 | reward: 5.999999999999995 | done: False | action: 0.1742221564054489,-0.871813952922821
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 306 | reward: 4.0000000000000036 | done: False | action: 0.18078318238258362,-0.7975323796272278
torch.Size([364])
step: 307 | reward: 2.0000000000000018 | done: False | action: 0.19675375521183014,-0.785905122756958
torch.Size([364])
step: 308 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7679324746131897
torch.Size([364])
step: 309 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8045601844787598
torch.Size([364])
step: 310 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8323858976364136
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 311 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 312 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8675669431686401
torch.Size([364])
step: 313 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 314 | reward: -8.0 | done: False | action: 0.18036425113677979,-1.0
torch.Size([364])
step: 315 | reward: -8.0 | done: False | action: 0.18020091950893402,-0.9226795434951782
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 316 | reward: -8.0 | done: False | action: 0.18903174996376038,-0.672815203666687
torch.Size([364])
step: 317 | reward: -8.0 | done: False | action: 0.18830525875091553,-0.5389389395713806
torch.Size([364])
step: 318 | reward: -8.0 | done: False | action: 0.17513547837734222,-0.6403681039810181
torch.Size([364])
step: 319 | reward: -8.0 | done: False | action: 0.18247710168361664,-0.5882837176322937
torch.Size([364])
step: 320 | reward: -8.0 | done: False | action: 0.19250157475471497,-0.5390487909317017
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 321 | reward: -8.0 | done: False | action: 0.17918722331523895,-0.5650235414505005
torch.Size([364])
step: 322 | reward: -8.0 | done: False | action: 0.17404292523860931,-0.7093366980552673
torch.Size([364])
step: 323 | reward: -8.0 | done: False | action: 0.1809876263141632,-0.7968267798423767
torch.Size([364])
step: 324 | reward: -8.0 | done: False | action: 0.1663886308670044,-0.7800742387771606
torch.Size([364])
step: 325 | reward: -8.0 | done: False | action: 0.17996962368488312,-0.875882089138031
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 326 | reward: -8.0 | done: False | action: 0.17798927426338196,-0.9433176517486572
torch.Size([364])
step: 327 | reward: -8.0 | done: False | action: 0.17803317308425903,-1.0
torch.Size([364])
step: 328 | reward: 2.0000000000000018 | done: False | action: 0.173684760928154,-1.0
torch.Size([364])
step: 329 | reward: 2.0000000000000018 | done: False | action: 0.1471283882856369,-1.0
torch.Size([364])
step: 330 | reward: 2.0000000000000018 | done: False | action: 0.16573654115200043,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 331 | reward: 10.000000000000009 | done: False | action: 0.16494828462600708,-1.0
torch.Size([364])
step: 332 | reward: 6.000000000000005 | done: False | action: 0.15942087769508362,-0.9647493362426758
torch.Size([364])
step: 333 | reward: 5.999999999999983 | done: False | action: 0.1613791137933731,-0.9225876331329346
torch.Size([364])
step: 334 | reward: 4.0000000000000036 | done: False | action: 0.14609254896640778,-0.9197806715965271
torch.Size([364])
step: 335 | reward: 8.000000000000007 | done: False | action: 0.15106986463069916,-0.9310607314109802
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 336 | reward: 6.000000000000005 | done: False | action: 0.1363724172115326,-0.9267227053642273
torch.Size([364])
step: 337 | reward: 3.9999999999999813 | done: False | action: 0.15132291615009308,-0.914047360420227
torch.Size([364])
step: 338 | reward: 8.000000000000007 | done: False | action: 0.14770156145095825,-1.0
torch.Size([364])
step: 339 | reward: 4.0000000000000036 | done: False | action: 0.1396350860595703,-1.0
torch.Size([364])
step: 340 | reward: 2.0000000000000018 | done: False | action: 0.14887107908725739,-0.8631844520568848
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 341 | reward: 4.0000000000000036 | done: False | action: 0.17387214303016663,-0.8275172114372253
torch.Size([364])
step: 342 | reward: -8.0 | done: False | action: 0.19019336998462677,-0.7350645661354065
torch.Size([364])
step: 343 | reward: -8.0 | done: False | action: 0.19081048667430878,-0.6990082263946533
torch.Size([364])
step: 344 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.6792584657669067
torch.Size([364])
step: 345 | reward: -8.0 | done: False | action: 0.18200862407684326,-0.7821029424667358
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 346 | reward: -8.0 | done: False | action: 0.17878583073616028,-0.6776237487792969
torch.Size([364])
step: 347 | reward: -8.0 | done: False | action: 0.1866968274116516,-0.7127812504768372
torch.Size([364])
step: 348 | reward: -8.0 | done: False | action: 0.1921079009771347,-0.6453081369400024
torch.Size([364])
step: 349 | reward: -8.0 | done: False | action: 0.1932375282049179,-0.775671124458313
torch.Size([364])
step: 350 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8742250800132751
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 351 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 352 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 353 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 354 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 355 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 356 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 357 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 358 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.927187979221344
torch.Size([364])
step: 359 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9698763489723206
torch.Size([364])
step: 360 | reward: 1.9999999999999796 | done: False | action: 0.20000000298023224,-0.8925690054893494
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 361 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.6206098794937134
torch.Size([364])
step: 362 | reward: 4.0000000000000036 | done: False | action: 0.19571775197982788,-0.7052500247955322
torch.Size([364])
step: 363 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8974418640136719
torch.Size([364])
step: 364 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9094684720039368
torch.Size([364])
step: 365 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-0.9276923537254333
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 366 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 367 | reward: 6.000000000000005 | done: False | action: 0.18714539706707,-1.0
torch.Size([364])
step: 368 | reward: 9.999999999999986 | done: False | action: 0.19237476587295532,-1.0
torch.Size([364])
step: 369 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 370 | reward: 6.000000000000005 | done: False | action: 0.19988197088241577,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 371 | reward: 13.99999999999999 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 372 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 373 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 374 | reward: -8.0 | done: False | action: 0.1927666813135147,-0.816545844078064
torch.Size([364])
step: 375 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7231602072715759
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 376 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7939930558204651
torch.Size([364])
step: 377 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8625932335853577
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 5 --------------------
waiting for service
reset called
[INFO] [1650676841.650413, 1.133000]: Goal position : 1.2, -0.5
1.2 -0.5
torch.Size([364])
step: 378 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8728919625282288
torch.Size([364])
step: 379 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8752297759056091
torch.Size([364])
step: 380 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.7898449301719666
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 381 | reward: 18.000000000000014 | done: False | action: 0.20000000298023224,-0.9061548113822937
torch.Size([364])
step: 382 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.88643878698349
torch.Size([364])
step: 383 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.9081031680107117
torch.Size([364])
step: 384 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9872426390647888
torch.Size([364])
step: 385 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8491876125335693
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 386 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.887351930141449
torch.Size([364])
step: 387 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 388 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 389 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 390 | reward: -8.0 | done: False | action: 0.1980312466621399,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 391 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 392 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 393 | reward: -8.0 | done: False | action: 0.18699803948402405,-1.0
torch.Size([364])
step: 394 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9711176156997681
torch.Size([364])
step: 395 | reward: -8.0 | done: False | action: 0.19908080995082855,-0.8883687257766724
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 396 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 397 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 398 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9857314229011536
torch.Size([364])
step: 399 | reward: -8.0 | done: False | action: 0.19501173496246338,-1.0
torch.Size([364])
step: 400 | reward: -8.0 | done: False | action: 0.19491560757160187,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 401 | reward: -8.0 | done: False | action: 0.18925195932388306,-0.9587748646736145
torch.Size([364])
step: 402 | reward: -8.0 | done: False | action: 0.18576708436012268,-0.9732725620269775
torch.Size([364])
step: 403 | reward: -8.0 | done: False | action: 0.17823438346385956,-1.0
torch.Size([364])
step: 404 | reward: -8.0 | done: False | action: 0.19043751060962677,-1.0
torch.Size([364])
step: 405 | reward: 4.0000000000000036 | done: False | action: 0.19524896144866943,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 406 | reward: 4.0000000000000036 | done: False | action: 0.194820836186409,-1.0
torch.Size([364])
step: 407 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 408 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 409 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 410 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 411 | reward: 14.000000000000012 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 412 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.856451690196991
torch.Size([364])
step: 413 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-0.9242486953735352
torch.Size([364])
step: 414 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.949880838394165
torch.Size([364])
step: 415 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9397080540657043
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 416 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.7654791474342346
torch.Size([364])
step: 417 | reward: 2.0000000000000018 | done: False | action: 0.18478406965732574,-0.7605092525482178
torch.Size([364])
step: 418 | reward: 2.0000000000000018 | done: False | action: 0.18296056985855103,-0.8140121102333069
torch.Size([364])
step: 419 | reward: -8.0 | done: False | action: 0.183354914188385,-1.0
torch.Size([364])
step: 420 | reward: -8.0 | done: False | action: 0.1876043975353241,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 421 | reward: -8.0 | done: False | action: 0.17879943549633026,-1.0
torch.Size([364])
step: 422 | reward: -8.0 | done: False | action: 0.17122851312160492,-1.0
torch.Size([364])
step: 423 | reward: -8.0 | done: False | action: 0.17446956038475037,-1.0
torch.Size([364])
step: 424 | reward: -8.0 | done: False | action: 0.18397566676139832,-1.0
torch.Size([364])
step: 425 | reward: -8.0 | done: False | action: 0.1781504899263382,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 426 | reward: -8.0 | done: False | action: 0.19388464093208313,-1.0
torch.Size([364])
step: 427 | reward: -8.0 | done: False | action: 0.186650350689888,-1.0
torch.Size([364])
step: 428 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 429 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8750900626182556
torch.Size([364])
step: 430 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 431 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 432 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9925081729888916
torch.Size([364])
step: 433 | reward: -8.0 | done: False | action: 0.19756478071212769,-1.0
torch.Size([364])
step: 434 | reward: 2.0000000000000018 | done: False | action: 0.18348389863967896,-1.0
torch.Size([364])
step: 435 | reward: 4.0000000000000036 | done: False | action: 0.19289952516555786,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 436 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 437 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 438 | reward: 6.000000000000005 | done: False | action: 0.19337572157382965,-1.0
torch.Size([364])
step: 439 | reward: 8.000000000000007 | done: False | action: 0.18407127261161804,-1.0
torch.Size([364])
step: 440 | reward: 6.000000000000005 | done: False | action: 0.17894963920116425,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 441 | reward: 15.99999999999997 | done: False | action: 0.19329914450645447,-1.0
torch.Size([364])
step: 442 | reward: 8.000000000000007 | done: False | action: 0.19080710411071777,-1.0
torch.Size([364])
step: 443 | reward: 6.000000000000005 | done: False | action: 0.19351106882095337,-1.0
torch.Size([364])
step: 444 | reward: 6.000000000000005 | done: False | action: 0.18416889011859894,-1.0
torch.Size([364])
step: 445 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 446 | reward: 4.0000000000000036 | done: False | action: 0.19746088981628418,-1.0
torch.Size([364])
step: 447 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 448 | reward: -8.0 | done: False | action: 0.19531117379665375,-1.0
torch.Size([364])
step: 449 | reward: -8.0 | done: False | action: 0.19152601063251495,-1.0
torch.Size([364])
step: 450 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9871670007705688
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 451 | reward: -8.0 | done: False | action: 0.1886768341064453,-1.0
torch.Size([364])
step: 452 | reward: -8.0 | done: False | action: 0.17887704074382782,-0.9365347027778625
torch.Size([364])
step: 453 | reward: -8.0 | done: False | action: 0.1789911687374115,-0.9209780097007751
torch.Size([364])
step: 454 | reward: -8.0 | done: False | action: 0.17603163421154022,-0.918410062789917
torch.Size([364])
step: 455 | reward: -8.0 | done: False | action: 0.18577763438224792,-0.919215738773346
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 456 | reward: -8.0 | done: False | action: 0.16969457268714905,-0.9123485088348389
torch.Size([364])
step: 457 | reward: -8.0 | done: False | action: 0.16905398666858673,-0.904613196849823
torch.Size([364])
step: 458 | reward: -8.0 | done: False | action: 0.17203259468078613,-0.8661293983459473
torch.Size([364])
step: 459 | reward: -8.0 | done: False | action: 0.1588555872440338,-0.9839533567428589
torch.Size([364])
step: 460 | reward: -8.0 | done: False | action: 0.15913359820842743,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 461 | reward: -8.0 | done: False | action: 0.16387847065925598,-1.0
torch.Size([364])
step: 462 | reward: -8.0 | done: False | action: 0.1632271558046341,-1.0
torch.Size([364])
step: 463 | reward: 2.0000000000000018 | done: False | action: 0.17853520810604095,-0.9638665914535522
torch.Size([364])
step: 464 | reward: 2.0000000000000018 | done: False | action: 0.19051074981689453,-0.8256537318229675
torch.Size([364])
step: 465 | reward: 4.0000000000000036 | done: False | action: 0.19192703068256378,-0.858100175857544
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 466 | reward: 6.000000000000005 | done: False | action: 0.18832607567310333,-0.8449815511703491
torch.Size([364])
step: 467 | reward: 6.000000000000005 | done: False | action: 0.18825404345989227,-0.8445707559585571
torch.Size([364])
step: 468 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.7062072157859802
torch.Size([364])
step: 469 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8553416728973389
torch.Size([364])
step: 470 | reward: 9.999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 471 | reward: 14.000000000000012 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 472 | reward: 6.000000000000005 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 473 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 474 | reward: 2.0000000000000018 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 475 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 476 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 477 | reward: -8.0 | done: False | action: 0.0,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 6 --------------------
waiting for service
reset called
[INFO] [1650676865.150615, 1.183000]: Goal position : -1.1, -0.9
-1.1 -0.9
torch.Size([364])
step: 478 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 479 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 480 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 481 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 482 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 483 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 484 | reward: 2.0000000000000018 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 485 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 486 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 487 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 488 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 489 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 490 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 491 | reward: 2.0000000000000018 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 492 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 493 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 494 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 495 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 496 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 497 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 498 | reward: -8.0 | done: False | action: 0.0,-0.9030656218528748
torch.Size([364])
step: 499 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 500 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 501 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 502 | reward: -8.0 | done: False | action: 0.0,-0.9791662693023682
torch.Size([364])
step: 503 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 504 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 505 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 506 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 507 | reward: -8.0 | done: False | action: 0.0,-0.7978138327598572
torch.Size([364])
step: 508 | reward: -8.0 | done: False | action: 0.0,-0.8902214765548706
torch.Size([364])
step: 509 | reward: -8.0 | done: False | action: 0.0,-0.9070385098457336
torch.Size([364])
step: 510 | reward: -8.0 | done: False | action: 0.007964794524013996,-0.8665527701377869
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 511 | reward: -8.0 | done: False | action: 0.0036510855425149202,-0.8411248922348022
torch.Size([364])
step: 512 | reward: 2.0000000000000018 | done: False | action: 0.03430401161313057,-0.9282950162887573
torch.Size([364])
step: 513 | reward: -8.0 | done: False | action: 0.037925392389297485,-0.8571974039077759
torch.Size([364])
step: 514 | reward: 2.0000000000000018 | done: False | action: 0.03070659376680851,-0.909641683101654
torch.Size([364])
step: 515 | reward: -8.0 | done: False | action: 0.02314363606274128,-0.7765210270881653
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 516 | reward: 2.0000000000000018 | done: False | action: 0.03314824029803276,-0.7631828188896179
torch.Size([364])
step: 517 | reward: 2.0000000000000018 | done: False | action: 0.036580488085746765,-0.8175522685050964
torch.Size([364])
step: 518 | reward: 2.0000000000000018 | done: False | action: 0.03576907515525818,-0.6773452162742615
torch.Size([364])
step: 519 | reward: 1.9999999999999574 | done: False | action: 0.03809018060564995,-0.6609024405479431
torch.Size([364])
step: 520 | reward: -8.0 | done: False | action: 0.01845027133822441,-0.7685346603393555
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 521 | reward: 2.0000000000000018 | done: False | action: 0.0,-0.8333127498626709
torch.Size([364])
step: 522 | reward: -8.0 | done: False | action: 0.0,-0.9133172035217285
torch.Size([364])
step: 523 | reward: -8.0 | done: False | action: 0.0,-0.7257776856422424
torch.Size([364])
step: 524 | reward: 2.0000000000000018 | done: False | action: 0.0,-0.8166918158531189
torch.Size([364])
step: 525 | reward: -8.0 | done: False | action: 0.004545892588794231,-0.7421382069587708
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 526 | reward: -8.0 | done: False | action: 0.0,-0.8106715083122253
torch.Size([364])
step: 527 | reward: -8.0 | done: False | action: 0.0,-0.895767331123352
torch.Size([364])
step: 528 | reward: -8.0 | done: False | action: 0.0,-0.9335724711418152
torch.Size([364])
step: 529 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 530 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 531 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 532 | reward: -8.0 | done: False | action: 0.006346362177282572,-1.0
torch.Size([364])
step: 533 | reward: -8.0 | done: False | action: 0.011507190763950348,-1.0
torch.Size([364])
step: 534 | reward: -8.0 | done: False | action: 0.014081543311476707,-1.0
torch.Size([364])
step: 535 | reward: -8.0 | done: False | action: 0.004364653956145048,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 536 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 537 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 538 | reward: -8.0 | done: False | action: 0.0009444478200748563,-1.0
torch.Size([364])
step: 539 | reward: -8.0 | done: False | action: 0.003764796070754528,-1.0
torch.Size([364])
step: 540 | reward: -8.0 | done: False | action: 0.010859991423785686,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 541 | reward: -8.0 | done: False | action: 0.008540507405996323,-1.0
torch.Size([364])
step: 542 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 543 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 544 | reward: 1.9999999999999574 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 545 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 546 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 547 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 548 | reward: -8.0 | done: False | action: 0.0016530158463865519,-0.9117314219474792
torch.Size([364])
step: 549 | reward: -8.0 | done: False | action: 0.0,-0.9803774952888489
torch.Size([364])
step: 550 | reward: -8.0 | done: False | action: 0.0,-0.9198592305183411
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 551 | reward: 2.0000000000000018 | done: False | action: 0.0,-0.8203179836273193
torch.Size([364])
step: 552 | reward: -8.0 | done: False | action: 0.0,-0.9036888480186462
torch.Size([364])
step: 553 | reward: -8.0 | done: False | action: 0.0,-0.9535316824913025
torch.Size([364])
step: 554 | reward: -8.0 | done: False | action: 0.0,-0.9529419541358948
torch.Size([364])
step: 555 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 556 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 557 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 558 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 559 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 560 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 561 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 562 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 563 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 564 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 565 | reward: -8.0 | done: False | action: 0.0,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 566 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 567 | reward: -8.0 | done: False | action: 0.0065154810436069965,-1.0
torch.Size([364])
step: 568 | reward: -8.0 | done: False | action: 0.005257105454802513,-1.0
torch.Size([364])
step: 569 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 570 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 571 | reward: -8.0 | done: False | action: 0.0,-1.0
torch.Size([364])
step: 572 | reward: -8.0 | done: False | action: 0.0,-0.9571546316146851
torch.Size([364])
step: 573 | reward: -8.0 | done: False | action: 0.0,-0.770146906375885
torch.Size([364])
step: 574 | reward: -8.0 | done: False | action: 0.0,-0.9347066879272461
torch.Size([364])
step: 575 | reward: 1.9999999999999574 | done: False | action: 0.013557778671383858,-0.7445003986358643
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 576 | reward: -8.0 | done: False | action: 0.016094140708446503,-0.8036722540855408
torch.Size([364])
step: 577 | reward: 2.0000000000000018 | done: False | action: 0.041331544518470764,-0.701330840587616
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 7 --------------------
waiting for service
reset called
[INFO] [1650676889.249415, 1.072000]: Goal position : 0.9, -0.1
0.9 -0.1
torch.Size([364])
step: 578 | reward: -8.0 | done: False | action: 0.02773706428706646,-0.6324790120124817
torch.Size([364])
step: 579 | reward: -8.0 | done: False | action: 0.010919587686657906,-0.7762002348899841
torch.Size([364])
step: 580 | reward: 2.0000000000000018 | done: False | action: 0.022352004423737526,-0.8105031251907349
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 581 | reward: 2.0000000000000018 | done: False | action: 0.03042137250304222,-0.7707529664039612
torch.Size([364])
step: 582 | reward: -8.0 | done: False | action: 0.026434728875756264,-0.7669900059700012
torch.Size([364])
step: 583 | reward: 2.0000000000000018 | done: False | action: 0.022041451185941696,-0.6652041077613831
torch.Size([364])
step: 584 | reward: -8.0 | done: False | action: 0.022059042006731033,-0.8887529373168945
torch.Size([364])
step: 585 | reward: -8.0 | done: False | action: 0.024257328361272812,-0.8031359314918518
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 586 | reward: -8.0 | done: False | action: 0.018321117386221886,-0.8101450800895691
torch.Size([364])
step: 587 | reward: 2.0000000000000018 | done: False | action: 0.02300281822681427,-0.8845992684364319
torch.Size([364])
step: 588 | reward: -8.0 | done: False | action: 0.02643740549683571,-1.0
torch.Size([364])
step: 589 | reward: -8.0 | done: False | action: 0.016409534960985184,-1.0
torch.Size([364])
step: 590 | reward: -8.0 | done: False | action: 0.017515841871500015,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 591 | reward: -8.0 | done: False | action: 0.19769006967544556,-1.0
torch.Size([364])
step: 592 | reward: -8.0 | done: False | action: 0.1878809928894043,-1.0
torch.Size([364])
step: 593 | reward: -8.0 | done: False | action: 0.19703425467014313,-1.0
torch.Size([364])
step: 594 | reward: -8.0 | done: False | action: 0.1863665133714676,-1.0
torch.Size([364])
step: 595 | reward: -8.0 | done: False | action: 0.18560802936553955,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 596 | reward: -8.0 | done: False | action: 0.1685333400964737,-1.0
torch.Size([364])
step: 597 | reward: -8.0 | done: False | action: 0.1638212352991104,-1.0
torch.Size([364])
step: 598 | reward: -8.0 | done: False | action: 0.1646139770746231,-1.0
torch.Size([364])
step: 599 | reward: -8.0 | done: False | action: 0.16856113076210022,-1.0
torch.Size([364])
step: 600 | reward: -8.0 | done: False | action: 0.1728922426700592,-0.8737408518791199
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 601 | reward: -8.0 | done: False | action: 0.18108731508255005,-0.8678911924362183
torch.Size([364])
step: 602 | reward: 2.0000000000000018 | done: False | action: 0.1944955587387085,-0.9534204602241516
torch.Size([364])
step: 603 | reward: 4.0000000000000036 | done: False | action: 0.18004798889160156,-0.9578978419303894
torch.Size([364])
step: 604 | reward: 6.000000000000005 | done: False | action: 0.177571102976799,-0.9632633328437805
torch.Size([364])
step: 605 | reward: 6.000000000000005 | done: False | action: 0.19788821041584015,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 606 | reward: 6.000000000000005 | done: False | action: 0.1956171840429306,-1.0
torch.Size([364])
step: 607 | reward: 8.000000000000007 | done: False | action: 0.1968972533941269,-0.9202696084976196
torch.Size([364])
step: 608 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 609 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 610 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9734106659889221
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 611 | reward: 19.999999999999996 | done: False | action: 0.20000000298023224,-0.9417094588279724
torch.Size([364])
step: 612 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 613 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9766077399253845
torch.Size([364])
step: 614 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8717588782310486
torch.Size([364])
step: 615 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 616 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 617 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 618 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 619 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 620 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 621 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 622 | reward: -8.0 | done: False | action: 0.19630911946296692,-1.0
torch.Size([364])
step: 623 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 624 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 625 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9088549017906189
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 626 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9400097131729126
torch.Size([364])
step: 627 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7440988421440125
torch.Size([364])
step: 628 | reward: -8.0 | done: False | action: 0.18738873302936554,-0.7929067015647888
torch.Size([364])
step: 629 | reward: -8.0 | done: False | action: 0.1771538406610489,-0.8907437920570374
torch.Size([364])
step: 630 | reward: -8.0 | done: False | action: 0.1797201782464981,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 631 | reward: 6.000000000000005 | done: False | action: 0.1944258213043213,-0.9253285527229309
torch.Size([364])
step: 632 | reward: 4.0000000000000036 | done: False | action: 0.19482868909835815,-0.9886513352394104
torch.Size([364])
step: 633 | reward: 6.000000000000005 | done: False | action: 0.18902087211608887,-1.0
torch.Size([364])
step: 634 | reward: 6.000000000000005 | done: False | action: 0.19516369700431824,-1.0
torch.Size([364])
step: 635 | reward: 6.000000000000005 | done: False | action: 0.18966524302959442,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 636 | reward: 9.999999999999986 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 637 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 638 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 639 | reward: 7.999999999999985 | done: False | action: 0.19488686323165894,-1.0
torch.Size([364])
step: 640 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 641 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 642 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 643 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.980417788028717
torch.Size([364])
step: 644 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8771165609359741
torch.Size([364])
step: 645 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 646 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 647 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 648 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 649 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 650 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 651 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 652 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 653 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9750745892524719
torch.Size([364])
step: 654 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 655 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9123688340187073
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 656 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8442257642745972
torch.Size([364])
step: 657 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.947307825088501
torch.Size([364])
step: 658 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 659 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9713903069496155
torch.Size([364])
step: 660 | reward: 1.9999999999999574 | done: False | action: 0.19953656196594238,-0.903913676738739
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 661 | reward: 8.000000000000007 | done: False | action: 0.18872089684009552,-0.8645651936531067
torch.Size([364])
step: 662 | reward: 4.0000000000000036 | done: False | action: 0.19266217947006226,-0.8812841176986694
torch.Size([364])
step: 663 | reward: 8.000000000000007 | done: False | action: 0.19546125829219818,-0.8926852941513062
torch.Size([364])
step: 664 | reward: 6.000000000000005 | done: False | action: 0.1961653232574463,-0.9678805470466614
torch.Size([364])
step: 665 | reward: 8.000000000000007 | done: False | action: 0.193634033203125,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 666 | reward: 7.999999999999985 | done: False | action: 0.19767092168331146,-1.0
torch.Size([364])
step: 667 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8455837368965149
torch.Size([364])
step: 668 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 669 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-0.8846780061721802
torch.Size([364])
step: 670 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9049615859985352
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 671 | reward: 12.00000000000001 | done: False | action: 0.20000000298023224,-0.9013599753379822
torch.Size([364])
step: 672 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9655839800834656
torch.Size([364])
step: 673 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8248501420021057
torch.Size([364])
step: 674 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 675 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9810431003570557
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 676 | reward: -8.0 | done: False | action: 0.17840565741062164,-1.0
torch.Size([364])
step: 677 | reward: -8.0 | done: False | action: 0.1841839998960495,-0.9745919108390808
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 8 --------------------
waiting for service
reset called
[INFO] [1650676913.342834, 1.150000]: Goal position : -1.1, 0.1
-1.1 0.1
torch.Size([364])
step: 678 | reward: -8.0 | done: False | action: 0.18729326128959656,-0.9178878664970398
torch.Size([364])
step: 679 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 680 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 681 | reward: -8.0 | done: False | action: 0.19857287406921387,-1.0
torch.Size([364])
step: 682 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 683 | reward: -8.0 | done: False | action: 0.1901613175868988,-1.0
torch.Size([364])
step: 684 | reward: -8.0 | done: False | action: 0.19962599873542786,-1.0
torch.Size([364])
step: 685 | reward: -8.0 | done: False | action: 0.19831810891628265,-0.8695772290229797
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 686 | reward: -8.0 | done: False | action: 0.1907242089509964,-0.8039315342903137
torch.Size([364])
step: 687 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9659404158592224
torch.Size([364])
step: 688 | reward: -8.0 | done: False | action: 0.1939868927001953,-1.0
torch.Size([364])
step: 689 | reward: -8.0 | done: False | action: 0.18795017898082733,-0.8776960372924805
torch.Size([364])
step: 690 | reward: -8.0 | done: False | action: 0.19272930920124054,-0.9178099036216736
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 691 | reward: 9.999999999999964 | done: False | action: 0.19794602692127228,-0.9677144289016724
torch.Size([364])
step: 692 | reward: 6.000000000000005 | done: False | action: 0.19696664810180664,-1.0
torch.Size([364])
step: 693 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 694 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 695 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.997592568397522
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 696 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-0.9853690266609192
torch.Size([364])
step: 697 | reward: 5.999999999999961 | done: False | action: 0.1888570487499237,-1.0
torch.Size([364])
step: 698 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 699 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 700 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9862751960754395
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 701 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 702 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 703 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 704 | reward: -8.0 | done: False | action: 0.18868209421634674,-0.9318613409996033
torch.Size([364])
step: 705 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 706 | reward: -8.0 | done: False | action: 0.19382759928703308,-1.0
torch.Size([364])
step: 707 | reward: -8.0 | done: False | action: 0.19164970517158508,-0.9835391640663147
torch.Size([364])
step: 708 | reward: -8.0 | done: False | action: 0.1828656792640686,-0.9487510919570923
torch.Size([364])
step: 709 | reward: -8.0 | done: False | action: 0.18977130949497223,-0.9300808310508728
torch.Size([364])
step: 710 | reward: -8.0 | done: False | action: 0.1984817385673523,-0.9709373116493225
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 711 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 712 | reward: -8.0 | done: False | action: 0.19649159908294678,-0.9966910481452942
torch.Size([364])
step: 713 | reward: -8.0 | done: False | action: 0.18824829161167145,-1.0
torch.Size([364])
step: 714 | reward: -8.0 | done: False | action: 0.18195661902427673,-1.0
torch.Size([364])
step: 715 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9675375819206238
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 716 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9826452136039734
torch.Size([364])
step: 717 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9274343252182007
torch.Size([364])
step: 718 | reward: 1.9999999999999574 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 719 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9921260476112366
torch.Size([364])
step: 720 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 721 | reward: 14.000000000000012 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 722 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9605157971382141
torch.Size([364])
step: 723 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9650389552116394
torch.Size([364])
step: 724 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 725 | reward: 9.999999999999964 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 726 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 727 | reward: 6.000000000000005 | done: False | action: 0.19010578095912933,-0.9176977276802063
torch.Size([364])
step: 728 | reward: 6.000000000000005 | done: False | action: 0.18662738800048828,-0.9026744961738586
torch.Size([364])
step: 729 | reward: 4.0000000000000036 | done: False | action: 0.17900800704956055,-1.0
torch.Size([364])
step: 730 | reward: 2.0000000000000018 | done: False | action: 0.18809863924980164,-0.9795952439308167
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 731 | reward: -8.0 | done: False | action: 0.18871338665485382,-1.0
torch.Size([364])
step: 732 | reward: -8.0 | done: False | action: 0.18895256519317627,-1.0
torch.Size([364])
step: 733 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 734 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9616844058036804
torch.Size([364])
step: 735 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.966284453868866
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 736 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 737 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9129735231399536
torch.Size([364])
step: 738 | reward: -8.0 | done: False | action: 0.19240686297416687,-1.0
torch.Size([364])
step: 739 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9967769384384155
torch.Size([364])
step: 740 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 741 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 742 | reward: -8.0 | done: False | action: 0.19835123419761658,-1.0
torch.Size([364])
step: 743 | reward: -8.0 | done: False | action: 0.17636267840862274,-1.0
torch.Size([364])
step: 744 | reward: -8.0 | done: False | action: 0.18194995820522308,-0.986868143081665
torch.Size([364])
step: 745 | reward: 2.0000000000000018 | done: False | action: 0.19271212816238403,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 746 | reward: 1.9999999999999574 | done: False | action: 0.19878645241260529,-1.0
torch.Size([364])
step: 747 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 748 | reward: 4.0000000000000036 | done: False | action: 0.19334937632083893,-1.0
torch.Size([364])
step: 749 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 750 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 751 | reward: 16.000000000000014 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 752 | reward: 8.000000000000007 | done: False | action: 0.18527251482009888,-1.0
torch.Size([364])
step: 753 | reward: 9.999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 754 | reward: 6.000000000000005 | done: False | action: 0.19576102495193481,-1.0
torch.Size([364])
step: 755 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 756 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 757 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 758 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 759 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 760 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 761 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 762 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 763 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 764 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 765 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 766 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9927057027816772
torch.Size([364])
step: 767 | reward: -8.0 | done: False | action: 0.1954239010810852,-0.9463661313056946
torch.Size([364])
step: 768 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9831460118293762
torch.Size([364])
step: 769 | reward: -8.0 | done: False | action: 0.19539529085159302,-1.0
torch.Size([364])
step: 770 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 771 | reward: -8.0 | done: False | action: 0.1955365091562271,-1.0
torch.Size([364])
step: 772 | reward: 2.0000000000000018 | done: False | action: 0.19690576195716858,-1.0
torch.Size([364])
step: 773 | reward: 3.999999999999959 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 774 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 775 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 776 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 777 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 9 --------------------
waiting for service
reset called
[INFO] [1650676937.647063, 1.003000]: Goal position : 1.1, 0.4
1.1 0.4
torch.Size([364])
step: 778 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9982567429542542
torch.Size([364])
step: 779 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 780 | reward: 5.999999999999961 | done: False | action: 0.1976795196533203,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 781 | reward: 14.000000000000012 | done: False | action: 0.19576460123062134,-1.0
torch.Size([364])
step: 782 | reward: 2.0000000000000018 | done: False | action: 0.19039593636989594,-1.0
torch.Size([364])
step: 783 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 784 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 785 | reward: -8.0 | done: False | action: 0.18976472318172455,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 786 | reward: -8.0 | done: False | action: 0.17821812629699707,-1.0
torch.Size([364])
step: 787 | reward: -8.0 | done: False | action: 0.17272423207759857,-1.0
torch.Size([364])
step: 788 | reward: -8.0 | done: False | action: 0.18008151650428772,-1.0
torch.Size([364])
step: 789 | reward: -8.0 | done: False | action: 0.19053900241851807,-1.0
torch.Size([364])
step: 790 | reward: -8.0 | done: False | action: 0.19106881320476532,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 791 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 792 | reward: -8.0 | done: False | action: 0.1970619261264801,-1.0
torch.Size([364])
step: 793 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 794 | reward: -8.0 | done: False | action: 0.19321265816688538,-1.0
torch.Size([364])
step: 795 | reward: -8.0 | done: False | action: 0.19353115558624268,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 796 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 797 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 798 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 799 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 800 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 801 | reward: 9.999999999999964 | done: False | action: 0.18437771499156952,-1.0
torch.Size([364])
step: 802 | reward: 8.000000000000007 | done: False | action: 0.19147439301013947,-1.0
torch.Size([364])
step: 803 | reward: 6.000000000000005 | done: False | action: 0.19614169001579285,-1.0
torch.Size([364])
step: 804 | reward: 10.000000000000009 | done: False | action: 0.18026375770568848,-1.0
torch.Size([364])
step: 805 | reward: 8.000000000000007 | done: False | action: 0.19300302863121033,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 806 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 807 | reward: 5.999999999999961 | done: False | action: 0.20000000298023224,-0.9645930528640747
torch.Size([364])
step: 808 | reward: 10.000000000000009 | done: False | action: 0.19173872470855713,-0.9231840968132019
torch.Size([364])
step: 809 | reward: 6.000000000000005 | done: False | action: 0.18262746930122375,-1.0
torch.Size([364])
step: 810 | reward: 2.0000000000000018 | done: False | action: 0.18584169447422028,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 811 | reward: 4.0000000000000036 | done: False | action: 0.19319972395896912,-1.0
torch.Size([364])
step: 812 | reward: -8.0 | done: False | action: 0.19339245557785034,-0.8936228156089783
torch.Size([364])
step: 813 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 814 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 815 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 816 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9442407488822937
torch.Size([364])
step: 817 | reward: -8.0 | done: False | action: 0.18989114463329315,-0.946746826171875
torch.Size([364])
step: 818 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9464913010597229
torch.Size([364])
step: 819 | reward: -8.0 | done: False | action: 0.19214177131652832,-1.0
torch.Size([364])
step: 820 | reward: -8.0 | done: False | action: 0.19415244460105896,-0.9410536289215088
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 821 | reward: -8.0 | done: False | action: 0.18961180746555328,-0.8110697865486145
torch.Size([364])
step: 822 | reward: -8.0 | done: False | action: 0.17819178104400635,-0.8303841948509216
torch.Size([364])
step: 823 | reward: -8.0 | done: False | action: 0.1791502684354782,-0.88639235496521
torch.Size([364])
step: 824 | reward: -8.0 | done: False | action: 0.17451894283294678,-1.0
torch.Size([364])
step: 825 | reward: -8.0 | done: False | action: 0.1686103790998459,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 826 | reward: -8.0 | done: False | action: 0.16416104137897491,-1.0
torch.Size([364])
step: 827 | reward: -8.0 | done: False | action: 0.18296153843402863,-0.8875640034675598
torch.Size([364])
step: 828 | reward: 2.0000000000000018 | done: False | action: 0.17439106106758118,-0.9544795155525208
torch.Size([364])
step: 829 | reward: 2.0000000000000018 | done: False | action: 0.1801159828901291,-1.0
torch.Size([364])
step: 830 | reward: 6.000000000000005 | done: False | action: 0.17917503416538239,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 831 | reward: 7.999999999999963 | done: False | action: 0.17141492664813995,-0.9114105701446533
torch.Size([364])
step: 832 | reward: 8.000000000000007 | done: False | action: 0.180496945977211,-1.0
torch.Size([364])
step: 833 | reward: 6.000000000000005 | done: False | action: 0.19927151501178741,-1.0
torch.Size([364])
step: 834 | reward: 8.000000000000007 | done: False | action: 0.19021247327327728,-1.0
torch.Size([364])
step: 835 | reward: 8.000000000000007 | done: False | action: 0.18952134251594543,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 836 | reward: 8.000000000000007 | done: False | action: 0.18138596415519714,-1.0
torch.Size([364])
step: 837 | reward: 5.999999999999961 | done: False | action: 0.18379777669906616,-1.0
torch.Size([364])
step: 838 | reward: 8.000000000000007 | done: False | action: 0.18782925605773926,-1.0
torch.Size([364])
step: 839 | reward: 2.0000000000000018 | done: False | action: 0.17489515244960785,-1.0
torch.Size([364])
step: 840 | reward: 4.0000000000000036 | done: False | action: 0.18726186454296112,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 841 | reward: -8.0 | done: False | action: 0.1844877153635025,-1.0
torch.Size([364])
step: 842 | reward: -8.0 | done: False | action: 0.18191330134868622,-1.0
torch.Size([364])
step: 843 | reward: -8.0 | done: False | action: 0.18792133033275604,-1.0
torch.Size([364])
step: 844 | reward: -8.0 | done: False | action: 0.19614896178245544,-1.0
torch.Size([364])
step: 845 | reward: -8.0 | done: False | action: 0.17334160208702087,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 846 | reward: -8.0 | done: False | action: 0.17039388418197632,-0.7499751448631287
torch.Size([364])
step: 847 | reward: -8.0 | done: False | action: 0.17916461825370789,-0.7934280037879944
torch.Size([364])
step: 848 | reward: -8.0 | done: False | action: 0.17976419627666473,-0.8465164303779602
torch.Size([364])
step: 849 | reward: -8.0 | done: False | action: 0.1872294545173645,-0.782268762588501
torch.Size([364])
step: 850 | reward: -8.0 | done: False | action: 0.18122947216033936,-0.9140105247497559
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 851 | reward: -8.0 | done: False | action: 0.16918446123600006,-0.8741495013237
torch.Size([364])
step: 852 | reward: -8.0 | done: False | action: 0.17913909256458282,-0.7189663648605347
torch.Size([364])
step: 853 | reward: -8.0 | done: False | action: 0.1876349300146103,-0.7813218832015991
torch.Size([364])
step: 854 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7615605592727661
torch.Size([364])
step: 855 | reward: -8.0 | done: False | action: 0.19045628607273102,-0.8782691955566406
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 856 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9541035890579224
torch.Size([364])
step: 857 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9712686538696289
torch.Size([364])
step: 858 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 859 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9163323640823364
torch.Size([364])
step: 860 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.8393550515174866
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 861 | reward: 19.99999999999997 | done: False | action: 0.20000000298023224,-0.8506849408149719
torch.Size([364])
step: 862 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 863 | reward: 8.000000000000007 | done: False | action: 0.194083571434021,-1.0
torch.Size([364])
step: 864 | reward: 8.000000000000007 | done: False | action: 0.19581088423728943,-1.0
torch.Size([364])
step: 865 | reward: 10.000000000000009 | done: False | action: 0.18111330270767212,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 866 | reward: 6.000000000000005 | done: False | action: 0.19046162068843842,-1.0
torch.Size([364])
step: 867 | reward: 5.999999999999961 | done: False | action: 0.1981472373008728,-1.0
torch.Size([364])
step: 868 | reward: 6.000000000000005 | done: False | action: 0.19233717024326324,-1.0
torch.Size([364])
step: 869 | reward: 4.0000000000000036 | done: False | action: 0.18480587005615234,-1.0
torch.Size([364])
step: 870 | reward: 2.0000000000000018 | done: False | action: 0.183781236410141,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 871 | reward: -8.0 | done: False | action: 0.18582768738269806,-1.0
torch.Size([364])
step: 872 | reward: -8.0 | done: False | action: 0.17878147959709167,-1.0
torch.Size([364])
step: 873 | reward: -8.0 | done: False | action: 0.164769247174263,-1.0
torch.Size([364])
step: 874 | reward: -8.0 | done: False | action: 0.15936432778835297,-1.0
torch.Size([364])
step: 875 | reward: -8.0 | done: False | action: 0.15994331240653992,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 876 | reward: -8.0 | done: False | action: 0.1706038862466812,-1.0
torch.Size([364])
step: 877 | reward: -8.0 | done: False | action: 0.1798171103000641,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 10 --------------------
waiting for service
reset called
[INFO] [1650676961.748864, 1.185000]: Goal position : 1.0, -1.2
1.0 -1.2
torch.Size([364])
step: 878 | reward: 2.0000000000000018 | done: False | action: 0.1861906200647354,-0.9495221376419067
torch.Size([364])
step: 879 | reward: 2.0000000000000018 | done: False | action: 0.18074476718902588,-1.0
torch.Size([364])
step: 880 | reward: 6.000000000000005 | done: False | action: 0.16847370564937592,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 881 | reward: 14.000000000000012 | done: False | action: 0.1847763955593109,-1.0
torch.Size([364])
step: 882 | reward: 6.000000000000005 | done: False | action: 0.1864386647939682,-1.0
torch.Size([364])
step: 883 | reward: 7.999999999999963 | done: False | action: 0.18762485682964325,-1.0
torch.Size([364])
step: 884 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 885 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 886 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 887 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9958251714706421
torch.Size([364])
step: 888 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9083230495452881
torch.Size([364])
step: 889 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 890 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9627262353897095
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 891 | reward: -8.0 | done: False | action: 0.198669895529747,-1.0
torch.Size([364])
step: 892 | reward: -8.0 | done: False | action: 0.19212031364440918,-0.9425496459007263
torch.Size([364])
step: 893 | reward: -8.0 | done: False | action: 0.1939685046672821,-0.9519628286361694
torch.Size([364])
step: 894 | reward: -8.0 | done: False | action: 0.18458065390586853,-1.0
torch.Size([364])
step: 895 | reward: -8.0 | done: False | action: 0.1844034492969513,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 896 | reward: -8.0 | done: False | action: 0.1806626170873642,-1.0
torch.Size([364])
step: 897 | reward: -8.0 | done: False | action: 0.19332675635814667,-0.9042361378669739
torch.Size([364])
step: 898 | reward: -8.0 | done: False | action: 0.19035644829273224,-0.9579251408576965
torch.Size([364])
step: 899 | reward: -8.0 | done: False | action: 0.19381381571292877,-0.8997045159339905
torch.Size([364])
step: 900 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.994120180606842
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 901 | reward: -8.0 | done: False | action: 0.19265729188919067,-1.0
torch.Size([364])
step: 902 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 903 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9765613675117493
torch.Size([364])
step: 904 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9507348537445068
torch.Size([364])
step: 905 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 906 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 907 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9549480080604553
torch.Size([364])
step: 908 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 909 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9684171676635742
torch.Size([364])
step: 910 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9456804990768433
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 911 | reward: 17.99999999999997 | done: False | action: 0.20000000298023224,-0.9327282309532166
torch.Size([364])
step: 912 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9027818441390991
torch.Size([364])
step: 913 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9455905556678772
torch.Size([364])
step: 914 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.7724071741104126
torch.Size([364])
step: 915 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7594440579414368
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 916 | reward: 4.0000000000000036 | done: False | action: 0.19738073647022247,-0.662553608417511
torch.Size([364])
step: 917 | reward: 4.0000000000000036 | done: False | action: 0.19303390383720398,-0.7227752208709717
torch.Size([364])
step: 918 | reward: 4.0000000000000036 | done: False | action: 0.1945970058441162,-0.8314579725265503
torch.Size([364])
step: 919 | reward: 2.0000000000000018 | done: False | action: 0.19068019092082977,-0.7304924726486206
torch.Size([364])
step: 920 | reward: -8.0 | done: False | action: 0.1929347813129425,-0.5949914455413818
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 921 | reward: -8.0 | done: False | action: 0.18874236941337585,-0.6753003001213074
torch.Size([364])
step: 922 | reward: -8.0 | done: False | action: 0.1992103010416031,-0.6980177760124207
torch.Size([364])
step: 923 | reward: -8.0 | done: False | action: 0.19077451527118683,-0.8194469213485718
torch.Size([364])
step: 924 | reward: -8.0 | done: False | action: 0.1866355687379837,-0.7205246686935425
torch.Size([364])
step: 925 | reward: -8.0 | done: False | action: 0.17135481536388397,-0.8382816910743713
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 926 | reward: -8.0 | done: False | action: 0.17556840181350708,-0.7821990847587585
torch.Size([364])
step: 927 | reward: -8.0 | done: False | action: 0.17181280255317688,-0.8358924388885498
torch.Size([364])
step: 928 | reward: -8.0 | done: False | action: 0.1787366420030594,-0.8191236257553101
torch.Size([364])
step: 929 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7193893194198608
torch.Size([364])
step: 930 | reward: -8.0 | done: False | action: 0.19525587558746338,-0.637031614780426
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 931 | reward: -8.0 | done: False | action: 0.18637406826019287,-0.7512667179107666
torch.Size([364])
step: 932 | reward: -8.0 | done: False | action: 0.19173681735992432,-0.7704590559005737
torch.Size([364])
step: 933 | reward: -8.0 | done: False | action: 0.1902916133403778,-0.9466025233268738
torch.Size([364])
step: 934 | reward: -8.0 | done: False | action: 0.19666220247745514,-0.8232435584068298
torch.Size([364])
step: 935 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8316779732704163
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 936 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 937 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 938 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 939 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 940 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 941 | reward: 11.999999999999966 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 942 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 943 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 944 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9848988056182861
torch.Size([364])
step: 945 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 946 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9000678658485413
torch.Size([364])
step: 947 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.9126328229904175
torch.Size([364])
step: 948 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8368083238601685
torch.Size([364])
step: 949 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8775038123130798
torch.Size([364])
step: 950 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9008471369743347
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 951 | reward: 4.0000000000000036 | done: False | action: 0.19169674813747406,-0.7396373748779297
torch.Size([364])
step: 952 | reward: -8.0 | done: False | action: 0.18407724797725677,-0.9853048324584961
torch.Size([364])
step: 953 | reward: -8.0 | done: False | action: 0.1913081407546997,-1.0
torch.Size([364])
step: 954 | reward: -8.0 | done: False | action: 0.1741180270910263,-0.9703646302223206
torch.Size([364])
step: 955 | reward: -8.0 | done: False | action: 0.17494134604930878,-0.9017059803009033
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 956 | reward: -8.0 | done: False | action: 0.1718645691871643,-0.8659095168113708
torch.Size([364])
step: 957 | reward: -8.0 | done: False | action: 0.17884816229343414,-0.9780000448226929
torch.Size([364])
step: 958 | reward: -8.0 | done: False | action: 0.1759434938430786,-1.0
torch.Size([364])
step: 959 | reward: -8.0 | done: False | action: 0.17676249146461487,-0.9087239503860474
torch.Size([364])
step: 960 | reward: -8.0 | done: False | action: 0.19488832354545593,-0.9473116993904114
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 961 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9320738315582275
torch.Size([364])
step: 962 | reward: -8.0 | done: False | action: 0.1890326738357544,-1.0
torch.Size([364])
step: 963 | reward: -8.0 | done: False | action: 0.19484420120716095,-1.0
torch.Size([364])
step: 964 | reward: -8.0 | done: False | action: 0.18464739620685577,-1.0
torch.Size([364])
step: 965 | reward: -8.0 | done: False | action: 0.19850961863994598,-0.9578601121902466
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 966 | reward: -8.0 | done: False | action: 0.19768093526363373,-0.9821170568466187
torch.Size([364])
step: 967 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8818893432617188
torch.Size([364])
step: 968 | reward: 1.9999999999999574 | done: False | action: 0.18272338807582855,-0.8093999028205872
torch.Size([364])
step: 969 | reward: 4.0000000000000036 | done: False | action: 0.18995659053325653,-0.8511888384819031
torch.Size([364])
step: 970 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9356119632720947
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 971 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-0.9241943359375
torch.Size([364])
step: 972 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9123428463935852
torch.Size([364])
step: 973 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9217060804367065
torch.Size([364])
step: 974 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9671899080276489
torch.Size([364])
step: 975 | reward: 7.999999999999963 | done: False | action: 0.1917620748281479,-0.9481047987937927
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 976 | reward: 8.000000000000007 | done: False | action: 0.19614842534065247,-0.7262794375419617
torch.Size([364])
step: 977 | reward: 8.000000000000007 | done: False | action: 0.19234630465507507,-0.7738887667655945
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 11 --------------------
waiting for service
reset called
[INFO] [1650676985.845724, 1.112000]: Goal position : -0.1, 0.8
-0.1 0.8
torch.Size([364])
step: 978 | reward: -8.0 | done: False | action: 0.17813369631767273,-0.7034026980400085
torch.Size([364])
step: 979 | reward: -8.0 | done: False | action: 0.17054252326488495,-0.7460574507713318
torch.Size([364])
step: 980 | reward: -8.0 | done: False | action: 0.19962772727012634,-0.8956213593482971
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 981 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9509661793708801
torch.Size([364])
step: 982 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.948767364025116
torch.Size([364])
step: 983 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 984 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 985 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 986 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 987 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9939404726028442
torch.Size([364])
step: 988 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8115178346633911
torch.Size([364])
step: 989 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9543249011039734
torch.Size([364])
step: 990 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9619863629341125
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 991 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8932810425758362
torch.Size([364])
step: 992 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8025825023651123
torch.Size([364])
step: 993 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9501668214797974
torch.Size([364])
step: 994 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 995 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 996 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 997 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 998 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 999 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1000 | reward: 7.999999999999963 | done: False | action: 0.19896800816059113,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1001 | reward: 16.000000000000014 | done: False | action: 0.20000000298023224,-0.9748401045799255
torch.Size([364])
step: 1002 | reward: 8.000000000000007 | done: False | action: 0.19639496505260468,-0.9099457263946533
torch.Size([364])
step: 1003 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-0.9721762537956238
torch.Size([364])
step: 1004 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1005 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9293125867843628
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1006 | reward: 4.0000000000000036 | done: False | action: 0.17232690751552582,-0.783100962638855
torch.Size([364])
step: 1007 | reward: 2.0000000000000018 | done: False | action: 0.16749559342861176,-0.9573889374732971
torch.Size([364])
step: 1008 | reward: 2.0000000000000018 | done: False | action: 0.17445813119411469,-0.8893187642097473
torch.Size([364])
step: 1009 | reward: -8.0 | done: False | action: 0.17685453593730927,-0.8748020529747009
torch.Size([364])
step: 1010 | reward: -8.0 | done: False | action: 0.19281302392482758,-0.7328336238861084
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1011 | reward: -8.0 | done: False | action: 0.1909136325120926,-0.5937721729278564
torch.Size([364])
step: 1012 | reward: -8.0 | done: False | action: 0.1755332201719284,-0.6163326501846313
torch.Size([364])
step: 1013 | reward: -8.0 | done: False | action: 0.19001290202140808,-0.5794327259063721
torch.Size([364])
step: 1014 | reward: -8.0 | done: False | action: 0.1731244921684265,-0.660525918006897
torch.Size([364])
step: 1015 | reward: -8.0 | done: False | action: 0.17480264604091644,-0.6541711688041687
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1016 | reward: -8.0 | done: False | action: 0.17345499992370605,-0.5192372798919678
torch.Size([364])
step: 1017 | reward: -8.0 | done: False | action: 0.18436084687709808,-0.5248041749000549
torch.Size([364])
step: 1018 | reward: -8.0 | done: False | action: 0.19411906599998474,-0.6445658802986145
torch.Size([364])
step: 1019 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9716432094573975
torch.Size([364])
step: 1020 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1021 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9481725692749023
torch.Size([364])
step: 1022 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9637954831123352
torch.Size([364])
step: 1023 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9294445514678955
torch.Size([364])
step: 1024 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8537736535072327
torch.Size([364])
step: 1025 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9017811417579651
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1026 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1027 | reward: 2.0000000000000018 | done: False | action: 0.19676503539085388,-1.0
torch.Size([364])
step: 1028 | reward: 2.0000000000000018 | done: False | action: 0.19365447759628296,-0.9544212222099304
torch.Size([364])
step: 1029 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1030 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9709531664848328
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1031 | reward: 14.000000000000012 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1032 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1033 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.9980828762054443
torch.Size([364])
step: 1034 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9058151245117188
torch.Size([364])
step: 1035 | reward: 10.000000000000009 | done: False | action: 0.19856224954128265,-0.932594895362854
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1036 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8940843343734741
torch.Size([364])
step: 1037 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9434581398963928
torch.Size([364])
step: 1038 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1039 | reward: 5.999999999999983 | done: False | action: 0.1848549246788025,-1.0
torch.Size([364])
step: 1040 | reward: -8.0 | done: False | action: 0.17530842125415802,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1041 | reward: -8.0 | done: False | action: 0.1771998405456543,-1.0
torch.Size([364])
step: 1042 | reward: -8.0 | done: False | action: 0.18550091981887817,-1.0
torch.Size([364])
step: 1043 | reward: -8.0 | done: False | action: 0.1928083300590515,-1.0
torch.Size([364])
step: 1044 | reward: -8.0 | done: False | action: 0.1756906807422638,-1.0
torch.Size([364])
step: 1045 | reward: -8.0 | done: False | action: 0.16064876317977905,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1046 | reward: -8.0 | done: False | action: 0.1588357836008072,-1.0
torch.Size([364])
step: 1047 | reward: -8.0 | done: False | action: 0.16436271369457245,-1.0
torch.Size([364])
step: 1048 | reward: -8.0 | done: False | action: 0.15190865099430084,-1.0
torch.Size([364])
step: 1049 | reward: -8.0 | done: False | action: 0.1733536720275879,-1.0
torch.Size([364])
step: 1050 | reward: -8.0 | done: False | action: 0.17022274434566498,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1051 | reward: -8.0 | done: False | action: 0.16422753036022186,-1.0
torch.Size([364])
step: 1052 | reward: -8.0 | done: False | action: 0.1775190830230713,-1.0
torch.Size([364])
step: 1053 | reward: -8.0 | done: False | action: 0.18277722597122192,-1.0
torch.Size([364])
step: 1054 | reward: -8.0 | done: False | action: 0.1879102885723114,-0.9596013426780701
torch.Size([364])
step: 1055 | reward: -8.0 | done: False | action: 0.19437165558338165,-0.9003512859344482
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1056 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8027157187461853
torch.Size([364])
step: 1057 | reward: 2.0000000000000018 | done: False | action: 0.19277000427246094,-0.8100320100784302
torch.Size([364])
step: 1058 | reward: 2.0000000000000018 | done: False | action: 0.19968630373477936,-0.8467048406600952
torch.Size([364])
step: 1059 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.7574060559272766
torch.Size([364])
step: 1060 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.71727055311203
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1061 | reward: 11.999999999999966 | done: False | action: 0.19775386154651642,-0.6968310475349426
torch.Size([364])
step: 1062 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7944580912590027
torch.Size([364])
step: 1063 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8190338015556335
torch.Size([364])
step: 1064 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.989234209060669
torch.Size([364])
step: 1065 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1066 | reward: 5.999999999999983 | done: False | action: 0.18815648555755615,-1.0
torch.Size([364])
step: 1067 | reward: 8.000000000000007 | done: False | action: 0.1916067749261856,-1.0
torch.Size([364])
step: 1068 | reward: 6.000000000000005 | done: False | action: 0.1947384476661682,-1.0
torch.Size([364])
step: 1069 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1070 | reward: 3.9999999999999813 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1071 | reward: 4.0000000000000036 | done: False | action: 0.18512184917926788,-1.0
torch.Size([364])
step: 1072 | reward: -8.0 | done: False | action: 0.18650680780410767,-1.0
torch.Size([364])
step: 1073 | reward: -8.0 | done: False | action: 0.19640202820301056,-1.0
torch.Size([364])
step: 1074 | reward: -8.0 | done: False | action: 0.1988879293203354,-1.0
torch.Size([364])
step: 1075 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1076 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1077 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 12 --------------------
waiting for service
reset called
[INFO] [1650677009.342801, 1.078000]: Goal position : -0.1, -0.6
-0.1 -0.6
torch.Size([364])
step: 1078 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1079 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1080 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1081 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1082 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1083 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9835672378540039
torch.Size([364])
step: 1084 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9495876431465149
torch.Size([364])
step: 1085 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1086 | reward: 5.999999999999983 | done: False | action: 0.20000000298023224,-0.9639331102371216
torch.Size([364])
step: 1087 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1088 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1089 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1090 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1091 | reward: 18.000000000000004 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1092 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1093 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9948364496231079
torch.Size([364])
step: 1094 | reward: 3.9999999999999982 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1095 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1096 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1097 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9468336701393127
torch.Size([364])
step: 1098 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9161013960838318
torch.Size([364])
step: 1099 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8544527292251587
torch.Size([364])
step: 1100 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.892173171043396
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1101 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9019995927810669
torch.Size([364])
step: 1102 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9007631540298462
torch.Size([364])
step: 1103 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.929568350315094
torch.Size([364])
step: 1104 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8190302848815918
torch.Size([364])
step: 1105 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.6851590871810913
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1106 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8308700919151306
torch.Size([364])
step: 1107 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.874274730682373
torch.Size([364])
step: 1108 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.969719409942627
torch.Size([364])
step: 1109 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1110 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1111 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1112 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1113 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1114 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1115 | reward: 5.999999999999983 | done: False | action: 0.20000000298023224,-0.9866362810134888
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1116 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1117 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1118 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1119 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-0.9839164614677429
torch.Size([364])
step: 1120 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8902185559272766
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1121 | reward: 19.999999999999996 | done: False | action: 0.20000000298023224,-0.8170877695083618
torch.Size([364])
step: 1122 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8474575877189636
torch.Size([364])
step: 1123 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.6801073551177979
torch.Size([364])
step: 1124 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.6723480820655823
torch.Size([364])
step: 1125 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.4512611925601959
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1126 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.5722087025642395
torch.Size([364])
step: 1127 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8100006580352783
torch.Size([364])
step: 1128 | reward: -8.0 | done: False | action: 0.1992110311985016,-0.9295844435691833
torch.Size([364])
step: 1129 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8784744143486023
torch.Size([364])
step: 1130 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9662636518478394
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1131 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1132 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1133 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1134 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1135 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1136 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1137 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1138 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9597164392471313
torch.Size([364])
step: 1139 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9162315130233765
torch.Size([364])
step: 1140 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8977577090263367
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1141 | reward: 17.999999999999993 | done: False | action: 0.20000000298023224,-0.8632156848907471
torch.Size([364])
step: 1142 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8538410663604736
torch.Size([364])
step: 1143 | reward: 7.999999999999985 | done: False | action: 0.20000000298023224,-0.7059131860733032
torch.Size([364])
step: 1144 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.7125534415245056
torch.Size([364])
step: 1145 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-0.6902891993522644
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1146 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7488846778869629
torch.Size([364])
step: 1147 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-0.6914413571357727
torch.Size([364])
step: 1148 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-0.8693203926086426
torch.Size([364])
step: 1149 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.6790123581886292
torch.Size([364])
step: 1150 | reward: 7.9999999999999964 | done: False | action: 0.20000000298023224,-0.8125731348991394
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1151 | reward: 16.000000000000004 | done: False | action: 0.20000000298023224,-0.7685209512710571
torch.Size([364])
step: 1152 | reward: -8.0 | done: False | action: 0.19891470670700073,-0.7128984332084656
torch.Size([364])
step: 1153 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7189891934394836
torch.Size([364])
step: 1154 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8954081535339355
torch.Size([364])
step: 1155 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8008521795272827
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1156 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8325661420822144
torch.Size([364])
step: 1157 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7843685746192932
torch.Size([364])
step: 1158 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.6179043650627136
torch.Size([364])
step: 1159 | reward: -8.0 | done: False | action: 0.19445793330669403,-0.6112949252128601
torch.Size([364])
step: 1160 | reward: -8.0 | done: False | action: 0.19891658425331116,-0.7449436783790588
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1161 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7175818681716919
torch.Size([364])
step: 1162 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8717567920684814
torch.Size([364])
step: 1163 | reward: -8.0 | done: False | action: 0.1998593509197235,-0.9752985239028931
torch.Size([364])
step: 1164 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9385595917701721
torch.Size([364])
step: 1165 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1166 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9588640332221985
torch.Size([364])
step: 1167 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9540528059005737
torch.Size([364])
step: 1168 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8549065589904785
torch.Size([364])
step: 1169 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1170 | reward: 1.9999999999999796 | done: False | action: 0.19980528950691223,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1171 | reward: 14.000000000000012 | done: False | action: 0.18903541564941406,-1.0
torch.Size([364])
step: 1172 | reward: 4.0000000000000036 | done: False | action: 0.1911216825246811,-1.0
torch.Size([364])
step: 1173 | reward: 7.999999999999985 | done: False | action: 0.176173597574234,-1.0
torch.Size([364])
step: 1174 | reward: 6.000000000000005 | done: False | action: 0.18205668032169342,-1.0
torch.Size([364])
step: 1175 | reward: 8.000000000000007 | done: False | action: 0.16996416449546814,-0.7972162961959839
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1176 | reward: 7.9999999999999964 | done: False | action: 0.1946476399898529,-0.610924482345581
torch.Size([364])
step: 1177 | reward: 7.9999999999999964 | done: False | action: 0.199459969997406,-0.835293710231781
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 13 --------------------
waiting for service
reset called
[INFO] [1650677034.854136, 1.027000]: Goal position : -1.1, -0.6
-1.1 -0.6
torch.Size([364])
step: 1178 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7656887769699097
torch.Size([364])
step: 1179 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8494158983230591
torch.Size([364])
step: 1180 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.6991158723831177
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1181 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.821756899356842
torch.Size([364])
step: 1182 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9993206858634949
torch.Size([364])
step: 1183 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9710972309112549
torch.Size([364])
step: 1184 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9786635637283325
torch.Size([364])
step: 1185 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8689448833465576
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1186 | reward: -8.0 | done: False | action: 0.18703360855579376,-0.8553513884544373
torch.Size([364])
step: 1187 | reward: 2.0000000000000018 | done: False | action: 0.18244197964668274,-0.9848204851150513
torch.Size([364])
step: 1188 | reward: 4.0000000000000036 | done: False | action: 0.1849387139081955,-1.0
torch.Size([364])
step: 1189 | reward: 4.0000000000000036 | done: False | action: 0.18269337713718414,-1.0
torch.Size([364])
step: 1190 | reward: 4.0000000000000036 | done: False | action: 0.18109698593616486,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1191 | reward: 19.99999999999997 | done: False | action: 0.19040635228157043,-0.8780231475830078
torch.Size([364])
step: 1192 | reward: 10.000000000000009 | done: False | action: 0.17951150238513947,-0.8068273663520813
torch.Size([364])
step: 1193 | reward: 8.000000000000007 | done: False | action: 0.18893368542194366,-0.8327466249465942
torch.Size([364])
step: 1194 | reward: 6.000000000000005 | done: False | action: 0.19018740952014923,-0.8483732342720032
torch.Size([364])
step: 1195 | reward: 6.000000000000005 | done: False | action: 0.17926155030727386,-0.9804202914237976
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1196 | reward: 5.999999999999961 | done: False | action: 0.17912355065345764,-1.0
torch.Size([364])
step: 1197 | reward: 6.000000000000005 | done: False | action: 0.19003485143184662,-1.0
torch.Size([364])
step: 1198 | reward: 4.0000000000000036 | done: False | action: 0.1877446174621582,-1.0
torch.Size([364])
step: 1199 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9132391214370728
torch.Size([364])
step: 1200 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8511253595352173
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1201 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.907978892326355
torch.Size([364])
step: 1202 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8770151138305664
torch.Size([364])
step: 1203 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7914761900901794
torch.Size([364])
step: 1204 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9918899536132812
torch.Size([364])
step: 1205 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1206 | reward: -8.0 | done: False | action: 0.19720293581485748,-0.986399233341217
torch.Size([364])
step: 1207 | reward: -8.0 | done: False | action: 0.19037766754627228,-0.7861377000808716
torch.Size([364])
step: 1208 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7549795508384705
torch.Size([364])
step: 1209 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1210 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.998683512210846
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1211 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7948281168937683
torch.Size([364])
step: 1212 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8696090579032898
torch.Size([364])
step: 1213 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8937533497810364
torch.Size([364])
step: 1214 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9891591668128967
torch.Size([364])
step: 1215 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1216 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1217 | reward: 4.0000000000000036 | done: False | action: 0.17759276926517487,-1.0
torch.Size([364])
step: 1218 | reward: 7.999999999999963 | done: False | action: 0.18647077679634094,-1.0
torch.Size([364])
step: 1219 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9223476648330688
torch.Size([364])
step: 1220 | reward: 8.000000000000007 | done: False | action: 0.19655334949493408,-0.9848175048828125
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1221 | reward: 24.00000000000002 | done: False | action: 0.1842174232006073,-1.0
torch.Size([364])
step: 1222 | reward: 6.000000000000005 | done: False | action: 0.18935804069042206,-1.0
torch.Size([364])
step: 1223 | reward: 5.999999999999961 | done: False | action: 0.19375291466712952,-1.0
torch.Size([364])
step: 1224 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1225 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1226 | reward: -8.0 | done: False | action: 0.19729085266590118,-0.9959321618080139
torch.Size([364])
step: 1227 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1228 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1229 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1230 | reward: -8.0 | done: False | action: 0.18700721859931946,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1231 | reward: -8.0 | done: False | action: 0.1744830161333084,-1.0
torch.Size([364])
step: 1232 | reward: -8.0 | done: False | action: 0.17161370813846588,-1.0
torch.Size([364])
step: 1233 | reward: -8.0 | done: False | action: 0.18309831619262695,-0.9549754858016968
torch.Size([364])
step: 1234 | reward: -8.0 | done: False | action: 0.19043226540088654,-1.0
torch.Size([364])
step: 1235 | reward: -8.0 | done: False | action: 0.18667520582675934,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1236 | reward: -8.0 | done: False | action: 0.18599121272563934,-1.0
torch.Size([364])
step: 1237 | reward: -8.0 | done: False | action: 0.1893681138753891,-1.0
torch.Size([364])
step: 1238 | reward: -8.0 | done: False | action: 0.18507051467895508,-1.0
torch.Size([364])
step: 1239 | reward: -8.0 | done: False | action: 0.1915678083896637,-0.8807839751243591
torch.Size([364])
step: 1240 | reward: -8.0 | done: False | action: 0.1843876838684082,-0.8537297248840332
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1241 | reward: 4.0000000000000036 | done: False | action: 0.1938493847846985,-0.8169522881507874
torch.Size([364])
step: 1242 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.8711856603622437
torch.Size([364])
step: 1243 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9735689759254456
torch.Size([364])
step: 1244 | reward: 4.0000000000000036 | done: False | action: 0.19722333550453186,-1.0
torch.Size([364])
step: 1245 | reward: 5.999999999999961 | done: False | action: 0.19327715039253235,-0.9990728497505188
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1246 | reward: 10.000000000000009 | done: False | action: 0.19470469653606415,-1.0
torch.Size([364])
step: 1247 | reward: 8.000000000000007 | done: False | action: 0.19522324204444885,-1.0
torch.Size([364])
step: 1248 | reward: 8.000000000000007 | done: False | action: 0.18853212893009186,-1.0
torch.Size([364])
step: 1249 | reward: 6.000000000000005 | done: False | action: 0.1799893081188202,-1.0
torch.Size([364])
step: 1250 | reward: 6.000000000000005 | done: False | action: 0.15933626890182495,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1251 | reward: 15.99999999999997 | done: False | action: 0.168414905667305,-1.0
torch.Size([364])
step: 1252 | reward: 2.0000000000000018 | done: False | action: 0.1647489368915558,-0.9985110759735107
torch.Size([364])
step: 1253 | reward: 2.0000000000000018 | done: False | action: 0.168623685836792,-1.0
torch.Size([364])
step: 1254 | reward: -8.0 | done: False | action: 0.16996386647224426,-1.0
torch.Size([364])
step: 1255 | reward: -8.0 | done: False | action: 0.18468841910362244,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1256 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1257 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1258 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1259 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9842368364334106
torch.Size([364])
step: 1260 | reward: -8.0 | done: False | action: 0.19191712141036987,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1261 | reward: -8.0 | done: False | action: 0.18692578375339508,-1.0
torch.Size([364])
step: 1262 | reward: -8.0 | done: False | action: 0.17082926630973816,-1.0
torch.Size([364])
step: 1263 | reward: -8.0 | done: False | action: 0.18717379868030548,-0.9910407066345215
torch.Size([364])
step: 1264 | reward: -8.0 | done: False | action: 0.17597083747386932,-0.9399201273918152
torch.Size([364])
step: 1265 | reward: -8.0 | done: False | action: 0.16210180521011353,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1266 | reward: -8.0 | done: False | action: 0.15906953811645508,-1.0
torch.Size([364])
step: 1267 | reward: -8.0 | done: False | action: 0.15481175482273102,-0.9167724847793579
torch.Size([364])
step: 1268 | reward: -8.0 | done: False | action: 0.1670987904071808,-0.9417131543159485
torch.Size([364])
step: 1269 | reward: 2.0000000000000018 | done: False | action: 0.17356076836585999,-0.8870242238044739
torch.Size([364])
step: 1270 | reward: 2.0000000000000018 | done: False | action: 0.16336248815059662,-0.828388512134552
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1271 | reward: 8.000000000000007 | done: False | action: 0.15661099553108215,-0.7410591244697571
torch.Size([364])
step: 1272 | reward: 6.000000000000005 | done: False | action: 0.16173426806926727,-0.7363755702972412
torch.Size([364])
step: 1273 | reward: 3.999999999999959 | done: False | action: 0.15104424953460693,-0.936781108379364
torch.Size([364])
step: 1274 | reward: 6.000000000000005 | done: False | action: 0.17239585518836975,-0.8942260146141052
torch.Size([364])
step: 1275 | reward: 8.000000000000007 | done: False | action: 0.17667418718338013,-0.850775420665741
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1276 | reward: 8.000000000000007 | done: False | action: 0.1762228161096573,-0.9483510255813599
torch.Size([364])
step: 1277 | reward: 8.000000000000007 | done: False | action: 0.1967785805463791,-0.9287348985671997
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 14 --------------------
waiting for service
reset called
[INFO] [1650677060.366852, 1.183000]: Goal position : 0.8, 1.1
0.8 1.1
torch.Size([364])
step: 1278 | reward: -8.0 | done: False | action: 0.19524355232715607,-0.8119219541549683
torch.Size([364])
step: 1279 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.813643217086792
torch.Size([364])
step: 1280 | reward: 4.0000000000000036 | done: False | action: 0.1911790519952774,-0.9575305581092834
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1281 | reward: -8.0 | done: False | action: 0.18795853853225708,-1.0
torch.Size([364])
step: 1282 | reward: -8.0 | done: False | action: 0.18172907829284668,-1.0
torch.Size([364])
step: 1283 | reward: -8.0 | done: False | action: 0.19076107442378998,-1.0
torch.Size([364])
step: 1284 | reward: -8.0 | done: False | action: 0.1747906655073166,-0.9098110795021057
torch.Size([364])
step: 1285 | reward: -8.0 | done: False | action: 0.1806015819311142,-0.7486982345581055
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1286 | reward: -8.0 | done: False | action: 0.18541623651981354,-0.8201064467430115
torch.Size([364])
step: 1287 | reward: -8.0 | done: False | action: 0.16730090975761414,-0.8163965940475464
torch.Size([364])
step: 1288 | reward: -8.0 | done: False | action: 0.1778171807527542,-0.8144271969795227
torch.Size([364])
step: 1289 | reward: -8.0 | done: False | action: 0.19109240174293518,-0.72901850938797
torch.Size([364])
step: 1290 | reward: -8.0 | done: False | action: 0.18637844920158386,-0.6226444840431213
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1291 | reward: -8.0 | done: False | action: 0.17370302975177765,-0.6640990376472473
torch.Size([364])
step: 1292 | reward: -8.0 | done: False | action: 0.1813897341489792,-0.6929873824119568
torch.Size([364])
step: 1293 | reward: -8.0 | done: False | action: 0.18095122277736664,-0.6390947699546814
torch.Size([364])
step: 1294 | reward: -8.0 | done: False | action: 0.17328082025051117,-0.578027069568634
torch.Size([364])
step: 1295 | reward: -8.0 | done: False | action: 0.1756839156150818,-0.7153137922286987
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1296 | reward: -8.0 | done: False | action: 0.18782295286655426,-0.7886729836463928
torch.Size([364])
step: 1297 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8537049889564514
torch.Size([364])
step: 1298 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.7209092378616333
torch.Size([364])
step: 1299 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.7440052628517151
torch.Size([364])
step: 1300 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.8547871112823486
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1301 | reward: 16.000000000000014 | done: False | action: 0.20000000298023224,-0.6033796668052673
torch.Size([364])
step: 1302 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.5987787246704102
torch.Size([364])
step: 1303 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7384845614433289
torch.Size([364])
step: 1304 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7689919471740723
torch.Size([364])
step: 1305 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.8205894827842712
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1306 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.8340035080909729
torch.Size([364])
step: 1307 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9706588387489319
torch.Size([364])
step: 1308 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1309 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1310 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1311 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1312 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1313 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9730907678604126
torch.Size([364])
step: 1314 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8499742150306702
torch.Size([364])
step: 1315 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8643534183502197
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1316 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7872668504714966
torch.Size([364])
step: 1317 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7813747525215149
torch.Size([364])
step: 1318 | reward: -8.0 | done: False | action: 0.18633705377578735,-0.7464015483856201
torch.Size([364])
step: 1319 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8373964428901672
torch.Size([364])
step: 1320 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7474475502967834
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1321 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8346153497695923
torch.Size([364])
step: 1322 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9586918950080872
torch.Size([364])
step: 1323 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1324 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9756242632865906
torch.Size([364])
step: 1325 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1326 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1327 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1328 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.9907186627388
torch.Size([364])
step: 1329 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1330 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9670712351799011
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1331 | reward: 31.999999999999986 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1332 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1333 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1334 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1335 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1336 | reward: 2.0000000000000018 | done: False | action: 0.19810470938682556,-1.0
torch.Size([364])
step: 1337 | reward: 1.9999999999999574 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1338 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1339 | reward: -8.0 | done: False | action: 0.19092752039432526,-1.0
torch.Size([364])
step: 1340 | reward: -8.0 | done: False | action: 0.1839023381471634,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1341 | reward: -8.0 | done: False | action: 0.18371476233005524,-1.0
torch.Size([364])
step: 1342 | reward: -8.0 | done: False | action: 0.1875062733888626,-1.0
torch.Size([364])
step: 1343 | reward: -8.0 | done: False | action: 0.1838746815919876,-1.0
torch.Size([364])
step: 1344 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1345 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1346 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1347 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9941523671150208
torch.Size([364])
step: 1348 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1349 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1350 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1351 | reward: -8.0 | done: False | action: 0.19931119680404663,-1.0
torch.Size([364])
step: 1352 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1353 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1354 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1355 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9654527306556702
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1356 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9912946224212646
torch.Size([364])
step: 1357 | reward: 5.999999999999961 | done: False | action: 0.20000000298023224,-0.9882745742797852
torch.Size([364])
step: 1358 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1359 | reward: 12.00000000000001 | done: False | action: 0.20000000298023224,-0.956540584564209
torch.Size([364])
step: 1360 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1361 | reward: 20.000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1362 | reward: 3.999999999999959 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1363 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1364 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1365 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1366 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1367 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1368 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1369 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1370 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1371 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1372 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1373 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1374 | reward: -8.0 | done: False | action: 0.1902519315481186,-1.0
torch.Size([364])
step: 1375 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1376 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1377 | reward: -8.0 | done: False | action: 0.18352247774600983,-1.0
------------------------------------- EPISODE END -----------------------------------------
---------------------- EPISODE 15 --------------------
waiting for service
reset called
[INFO] [1650677087.276799, 1.171000]: Goal position : -1.1, 0.0
-1.1 0.0
torch.Size([364])
step: 1378 | reward: -8.0 | done: False | action: 0.17424902319908142,-1.0
torch.Size([364])
step: 1379 | reward: -8.0 | done: False | action: 0.17181052267551422,-1.0
torch.Size([364])
step: 1380 | reward: -8.0 | done: False | action: 0.18468526005744934,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1381 | reward: -8.0 | done: False | action: 0.16862991452217102,-1.0
torch.Size([364])
step: 1382 | reward: -8.0 | done: False | action: 0.17013996839523315,-1.0
torch.Size([364])
step: 1383 | reward: -8.0 | done: False | action: 0.16165359318256378,-1.0
torch.Size([364])
step: 1384 | reward: -8.0 | done: False | action: 0.17315146327018738,-1.0
torch.Size([364])
step: 1385 | reward: -8.0 | done: False | action: 0.1811419278383255,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1386 | reward: -8.0 | done: False | action: 0.1825585514307022,-1.0
torch.Size([364])
step: 1387 | reward: 2.0000000000000018 | done: False | action: 0.17626728117465973,-0.9672744274139404
torch.Size([364])
step: 1388 | reward: 2.0000000000000018 | done: False | action: 0.1826319396495819,-1.0
torch.Size([364])
step: 1389 | reward: 4.0000000000000036 | done: False | action: 0.18644607067108154,-0.9937402009963989
torch.Size([364])
step: 1390 | reward: 6.000000000000005 | done: False | action: 0.19092635810375214,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1391 | reward: 27.99999999999998 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1392 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1393 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1394 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1395 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1396 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1397 | reward: 1.9999999999999796 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1398 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1399 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9073506593704224
torch.Size([364])
step: 1400 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8846259117126465
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1401 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8665410876274109
torch.Size([364])
step: 1402 | reward: -8.0 | done: False | action: 0.19542284309864044,-0.8075873255729675
torch.Size([364])
step: 1403 | reward: -8.0 | done: False | action: 0.18312881886959076,-0.871054470539093
torch.Size([364])
step: 1404 | reward: -8.0 | done: False | action: 0.1810862123966217,-0.9607409238815308
torch.Size([364])
step: 1405 | reward: -8.0 | done: False | action: 0.18230076134204865,-0.8486847877502441
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1406 | reward: -8.0 | done: False | action: 0.18914075195789337,-0.7809877395629883
torch.Size([364])
step: 1407 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9046170115470886
torch.Size([364])
step: 1408 | reward: -8.0 | done: False | action: 0.19469384849071503,-1.0
torch.Size([364])
step: 1409 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1410 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1411 | reward: -8.0 | done: False | action: 0.18666291236877441,-1.0
torch.Size([364])
step: 1412 | reward: 2.0000000000000018 | done: False | action: 0.20000000298023224,-0.9832081198692322
torch.Size([364])
step: 1413 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1414 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1415 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1416 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1417 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1418 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1419 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1420 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1421 | reward: 24.00000000000002 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1422 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1423 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1424 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1425 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1426 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1427 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9551326632499695
torch.Size([364])
step: 1428 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1429 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9517015218734741
torch.Size([364])
step: 1430 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8222044706344604
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1431 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8768290877342224
torch.Size([364])
step: 1432 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7947821021080017
torch.Size([364])
step: 1433 | reward: -8.0 | done: False | action: 0.19110707938671112,-0.8763543963432312
torch.Size([364])
step: 1434 | reward: -8.0 | done: False | action: 0.195208340883255,-0.768014669418335
torch.Size([364])
step: 1435 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8450606465339661
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1436 | reward: -8.0 | done: False | action: 0.1974315494298935,-0.9959545135498047
torch.Size([364])
step: 1437 | reward: 2.0000000000000018 | done: False | action: 0.1825978308916092,-1.0
torch.Size([364])
step: 1438 | reward: 4.0000000000000036 | done: False | action: 0.19260957837104797,-0.8955756425857544
torch.Size([364])
step: 1439 | reward: 3.999999999999959 | done: False | action: 0.20000000298023224,-0.7859111428260803
torch.Size([364])
step: 1440 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.9330154061317444
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1441 | reward: 14.000000000000012 | done: False | action: 0.20000000298023224,-0.9948444962501526
torch.Size([364])
step: 1442 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9223435521125793
torch.Size([364])
step: 1443 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.708448052406311
torch.Size([364])
step: 1444 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.7474005818367004
torch.Size([364])
step: 1445 | reward: 7.999999999999963 | done: False | action: 0.20000000298023224,-0.664404034614563
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1446 | reward: 10.000000000000009 | done: False | action: 0.20000000298023224,-0.6404083967208862
torch.Size([364])
step: 1447 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.6952865719795227
torch.Size([364])
step: 1448 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.6864819526672363
torch.Size([364])
step: 1449 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-0.957207977771759
torch.Size([364])
step: 1450 | reward: 4.0000000000000036 | done: False | action: 0.20000000298023224,-0.7245323657989502
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1451 | reward: 5.999999999999983 | done: False | action: 0.20000000298023224,-0.6641156673431396
torch.Size([364])
step: 1452 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.7631130814552307
torch.Size([364])
step: 1453 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.8751993775367737
torch.Size([364])
step: 1454 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9470316767692566
torch.Size([364])
step: 1455 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9899826049804688
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1456 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1457 | reward: -8.0 | done: False | action: 0.20000000298023224,-0.9756067991256714
torch.Size([364])
step: 1458 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1459 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1460 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1461 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1462 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1463 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1464 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1465 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1466 | reward: -8.0 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1467 | reward: -8.0 | done: False | action: 0.1952897012233734,-1.0
torch.Size([364])
step: 1468 | reward: 4.0000000000000036 | done: False | action: 0.1969117969274521,-1.0
torch.Size([364])
step: 1469 | reward: 4.0000000000000036 | done: False | action: 0.18576961755752563,-0.9830834269523621
torch.Size([364])
step: 1470 | reward: 6.000000000000005 | done: False | action: 0.20000000298023224,-1.0
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
torch.Size([64, 364])
torch.Size([64, 364])
[34m-------------------- Agent Learning ---------------
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1471 | reward: 12.00000000000001 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1472 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-1.0
torch.Size([364])
step: 1473 | reward: 8.000000000000007 | done: False | action: 0.20000000298023224,-0.9851250648498535
torch.Size([364])
step: 1474 | reward: 9.999999999999964 | done: False | action: 0.20000000298023224,-0.9883691668510437
torch.Size([364])
step: 1475 | reward: 6.000000000000005 | done: False | action: 0.19823941588401794,-1.0
[31m-------------------- Updating Target Networks ---------------
torch.Size([364])
step: 1476 | reward: 8.000000000000007 | done: False | action: 0.19417421519756317,-1.0
torch.Size([364])
step: 1477 | reward: 6.000000000000005 | done: False | action: 0.1952447146177292,-0.9418944120407104
------------------------------------- EPISODE END -----------------------------------------
Completed Training
saving...
Traceback (most recent call last):
  File "train.py", line 136, in <module>
    run_training()
  File "train.py", line 128, in run_training
    agent.save(steps)
AttributeError: 'DDPGAgent' object has no attribute 'save'