exploration_decay_rate = 0.001

MAX_EPISODES = 15
MAX_STEPS = 1000
WAIT_STEPS = 1000
MAX_BUFFER = 50000
NETWORK_UPDATE = 12
SAVE_STEPS = 12
rewards_all_episodes = []

STATE_DIMENSION = 364
ACTION_DIMENSION = 2
ACTION_V_MAX = 0.2  # m/s
ACTION_W_MAX = 1  # rad/s
world = 'world_u'

BATCH_SIZE = 256
LEARNING_RATE = 0.001
GAMMA = 0.99
TAU = 0.001
